\addtocounter{wpno}{1}
\begin{Workpackage}{\thewpno}
\wplabel{wp:securityBigData}
\WPTitle{\wpname{\thewpno}}
\WPStart{Month 1}
\WPParticipant{UOD}{26}
\WPParticipant{SCCH}{18}
\WPParticipant{UCM}{10}
\WPParticipant{SOPRA}{7}
\WPParticipant{USTAN}{2}
\WPParticipant{IBM}{2}
\WPParticipant{YAG}{2}

\begin{WPObjectives}
The objectives of \theWP{} are to:
\begin{compactitem}
\item Identify security risks in use of systems for distributed storage of data inAI-based big data analytics;
%, targetting both distributed NoSQL databases such as ScyllaDB and MongoDb and plain distributed filesystems such as Hadoop HDFS; 
\item Identify security risks in use of parallel processing frameworks and high-level machine-learning libraries in AI-based big data analytics;
\item Develop novel mechanisms for evaluating and reducing privacy leakage in distributed AI;
%secure and privacy-preserving mechanisms for data release in machine learning based big data processing; \vjcomment{SCCH part}
\item Develop a novel framework for privacy-preserving transfer of knowledge extracted from private data sets;
%techniques for privacy-secured knowledge sharing in machine learning based AI systems; \vjcomment{SCCH part}
\item Adapt the self-healing mechanisms from WP2 to the big data analytics applications;
%Support semi-automatic repairing of the user code by integrating the self-healing mechanisms from WPXX into security and privacy-leakage diagnostics mechanisms for machine-learning based big data storage and analysis;
\end{compactitem}
\end{WPObjectives}

\begin{WPDescription}
The goal of this workpackage is to adapt vulnerability detection and self-healing techniques from WP2 to AI-based big data analytics applications. A typical big data analytics application uses a number of different layers of abstraction, from generic libraries for distributed filesystems and databases to specific, high-level machine-learning libraries. We will develop a framework that will be able to identify and repair security risks that appear in each different layer, as well as from the interaction between different layers. In  \ref{task:storage} we will focus on the data storage layer, identifying security vulnerabilities in the code that uses the chosen distributed databases and filesystems and, subsequently, repairing these vulnerabilities. %The choice of libraries used will be driven by the uses cases and will include Cassandra DB and Azure Data Lake, as well as plain distributed filesystems such as HDFS. 
\ref{task:processing} focuses on the layers of pattern-based big data processing frameworks and machine-learning libraries, such as MapReduce, Azure AI and Spark MLLib. \ref{task:privacyLeakage} focuses on evaluating and reducing privacy-leakage in distributed machine learning, by investigating optimal noise-adding mechanisms for preserving privacy. \ref{task:knowledgeSharing} investigates knowledge sharing in distributed machine learning, developing techniques for privacy-preserving transfer of knowledge extracted from large data sets. Collectively, the techniques from this work package will feed into the \TheProject{} methodology that will be developed in WP6. Each task will proceed in three phases. In the first phase, we will focus on the security and privacy vulnerabilities characteristic to deployment of applications in private clouds (demonstrated for all tasks in software deliverable~\ref{del:bigdata1}). This will enable us to develop fundamental techniques in a setting that exposes fewer vulnerabilities. In the second phase, we will extend the techniques to cover the issues in deploying the applications in public clouds (\ref{del:bigdata2}). This setting exposes many more vulnerabilities than the private clouds. In the third and final phase, we will adapt the developed techniques to deployment of applications in hybrid clouds, which may link private and public clouds or multiple public clouds (\ref{del:bigdata3}). 
\end{WPDescription}

\begin{Task}
\TaskTitle{Identifying and Repairing Vulnerabilities in Distributed Data Storage for AI-Based Big Data Analytics}
\TaskParticipant{UOD}{8}
\TaskParticipant{UCM}{5}
\TaskParticipant{SOPRA}{3}
\TaskParticipant{USTAN}{1}
\TaskParticipant{IBM}{1}
\TaskParticipant{YAG}{1}

\TaskStart{3}
\TaskEnd{33}
\TaskResults{%
\ref{del:bigdata1},
\ref{del:bigdata2},
\ref{del:bigdata3}
}
\TaskHeader{}
\tasklabel{task:storage}
In \theTask, we will define the methodology and conduct an analysis of vulnerabilities in usage of big data storage backends (such as NoSQL databases and distributed file systems such as Azure DL) for AI-based big data analytics.  We will select examples of NoSQL databases both constructed in C++ (or with C++ bindings for the end user code) and based on the JVM languages (Java and Scala for instance). For most of the part we will treat the databases and filesystems as black boxes, focusing on their usage rather than on their internals, but we will also, where feasible, identify vulnerabilities in the source code of the databases/filesystems bindings. This task will exploit the mechanisms for identification of security and privacy vulnerabilities from WP2 and adapt them to the specific issues arising in big data applications. In particular, side projects (such as language drivers) will be examined as these provide an attack vector that may be outside the open source projects control. We will also adapt the self-healing mechanisms from WP2 to the specific problem of big data storage considered in this task. 
\UODshort{} and \SOPRAshort{} will contribute to this task with their expertise in storage for big data analysis, selecting the appropriate databases/filesystems and applying the vulnerabilities detection and self-healing mechanisms developed in WP2 to them. 
\IBMshort{} and \YAGshort{} will provide consultancy for the use of their tools for source code analysis and symbolic execution. 
\UCMshort{} and \USTANshort{} will provide expertise in C++/Java source code analysis and refactoring for analysing and repairing C++/Java storage software components.
 \end{Task}

 \begin{Task}
 \TaskTitle{Identifying and Repairing Vulnerabilities in Distributed Pattern-Based AI-Based Data Analytics}
 \TaskParticipant{UOD}{14}
 \TaskParticipant{UCM}{5}
\TaskParticipant{SOPRA}{4}
\TaskParticipant{USTAN}{1}
\TaskParticipant{IBM}{1}
\TaskParticipant{YAG}{1}
 \TaskStart{3}
 \TaskEnd{36}
 \TaskResults{%
 \ref{del:bigdata1},
 \ref{del:bigdata2},
 \ref{del:bigdata3}
 }
 \TaskHeader{}
 \tasklabel{task:processing}
 In \theTask, we will address vulnerabilities in usage of pattern-based frameworks for big data processing. This task will cover both the generic processing frameworks such as MapReduce and the higher-level specific machine-learning libraries such as Azure AI. These frameworks are usually built on top of distributed filesystems and databases and are presented to the end users in the form of a library that encapsulates data and computations distributions. They provide their own security challenges beyond those in data storage systems, as the location where the data is processed can be different to where it is stored, resulting in possibly very frequent data transfers across nodes (or even organisations). The task will follow a similar pattern to that of \ref{task:storage} selecting candidates systems from those written in C++ or based on the JVM (Hadoop, Spark, Azure AI, Spark MLLib) exploiting source-code level analysis and using symbolic execution and runtime monitoring (WP2) to expose security vulnerabilities. In addition to that, we will also adapt the technologies for self-healing to the usage of big data processing frameworks. \UODshort{} will lead this task, contributing with its expertise in parallel processing frameworks and \SOPRAshort{} in big data analytics. \IBMshort{} and \YAGshort{} will provide consultancy for the use of their tools in discovering vulnerabilities in the targeted frameworks, as well as in application of the self-healing technologies. \UCM and \SA will help with vulnerability analysis and refactoring of software components.

\end{Task}
 
\begin{Task}
  \TaskTitle{Evaluation and Reduction in Private Data Leakage for Distributed Machine Learning Data Analytics}
  \TaskParticipant{SCCH}{9}
  \TaskParticipant{UOD}{2}
  
  \TaskStart{1}
  \TaskEnd{33}
  \TaskResults{%
  \ref{del:bigdata1}
   \ref{del:bigdata2}
   \ref{del:bigdata3}
  }
  \TaskHeader{}
  \tasklabel{task:privacyLeakage}
  In this task, we will develop mechanisms to evaluate and reduce information leakage in distributed machine learning data analytics systems. The methods for evaluation of privacy leakage will be investigated in terms of relationship between sensitive data and released public data. Our approach is to employ a stochastic model for approximating the uncertain mapping between released noise added data and private data. The stochastic model facilitates a variational approximation of privacy-leakage in-terms of mutual information between sensitive private data and released public data. For reducing information leakage, we will develop optimal noise adding mechanisms for preserving privacy. We will derive analytically the noise distribution that maximises a given utility function or equivalently minimises a given data distortion function. Different use cases may demand different utility functions and thus optimal noise adding mechanism is derived for each utility function separately. \SCCHshort{} will lead this task, contributing with its expertise in privacy of distributed machine learning. \UODshort{} will help with the adaptation of the developed techniques to large-scale big-data analytics. 

 \end{Task}

 \begin{Task}
  \TaskTitle{Privacy-Preserving Knowledge Sharing in Distributed AI}
  \TaskParticipant{SCCH}{9}
    \TaskParticipant{UOD}{2}

  \TaskStart{7}
  \TaskEnd{36}
  \TaskResults{%
    \ref{del:bigdata1}
   \ref{del:bigdata2}
   \ref{del:bigdata3}
  }
  \TaskHeader{}
  \tasklabel{task:knowledgeSharing}
  This task will develop an analytical framework to optimise the privacy-preserving transfer of knowledge extracted from a large set of labelled private data owned by a party to another party owning a few labelled data samples. The goal is to answer the question of how can a model be transferred from a source to a target domain while preserving privacy of both source and target domains. An information theoretic approach is considered to quantify transferability of knowledge from source to target domain in-terms of mutual information between source and target data. The privacy secured knowledge sharing framework facilitates development of transfer and multi-task machine learning algorithm while optimising the privacy-transferability tradeoff. \SCCHshort{} will lead this task with their expertise in privacy-preserving transfer of knowledge. \UODshort{} will contribute to the adaptation of this techniques for larger data sets present in big data analytics. 
 \end{Task}

 %%\begin{Task}
  %%\TaskTitle{Self-Healing in Distributed Data Processing Systems}
  %%\TaskParticipant{SCCH}{1}
  
  %%\TaskStart{1}
  %%\TaskEnd{36}
  %%\TaskResults{%
  %\ref{del:model1}
 %% }
  %%\TaskHeader{}
  %%\tasklabel{task:healing}
  %%In \theTask, we will integrate self-healing mechanisms developed in WPXX into the tools and techniques developed in this work package. Collectively, the diagnostics and repairs of security vulnerabilities developed in this work package will feed into the refactoring-based self-healing methodology from WP6. A sample use case from one of the technologies surveyed in \ref{task:storage}, \ref{task:processing}in  will be selected to demonstrate the application of self healing to that technology. 
 %%\end{Task}
 
 
% \begin{Task}
%  %\TaskTitle{Privacy-preserving Biometric Data}
%  \TaskTitle{Privacy-Preserving Biometric Data in Authentication for Big Data Systems}
%  \TaskParticipant{COGNI}{1}
%   \TaskParticipant{SCCH}{1}
%  
%  \TaskStart{1}
%  \TaskEnd{36}
%  \TaskResults{%
%  %\ref{del:model1}
%  }
%  \TaskHeader{}
%  \tasklabel{task:privacyBiometrics}
%  Bearing in mind that users' biometric data are irrevocable when exposed, it is very important to protect their privacy. In this task, new methods will be designed, developed and evaluated for preserving the privacy of the biometric data used for continuous authentication in WP5. Main aim of privacy-preserving biometric authentication is to enable users to verify themselves without disclosing raw and sensitive biometric information. For doing so, current privacy weaknesses and threats in biometric authentication will be analyzed, and novel privacy-preserving methods will be designed and developed to secure the implementation of biometric-based continuous authentication, such as, features' transformation, cancelable biometrics, pseudo-identities, etc.
% \end{Task}
% 
% 
%\begin{Task}
%\TaskTitle{Integration into \TheProject{} Front End User Interface}
%\TaskParticipant{YAG}{1}
%\TaskParticipant{SA}{1}
%\TaskStart{1}
%\TaskEnd{36}
%\TaskResults{%
%%\ref{del:model1}
%}
%\TaskHeader{}
%\tasklabel{task:PrivacyFromSAST}
%In \theTask, we will improve the static analysis tool and its post-processing algorithms to extend vulnerability detection to distributed data specific vulnerabilities, with a particular focus on privacy and anonymisation leaks. We will use as an input the description of the specific security and privacy vulnerabilities of distributed Machine learning to be identified in the task XX. We will integrate them in the static analysis detection and qualification algorithms. Programming languages to be scanned will be JAVA and C/C++.
%
%The SAST and post processing algorithms will be developed to support design flaws in order to detect anonymization vulnerabilities and risks.
%
%The vulnerability detection will include a business oriented semantics approach in order to support multilevel privacy and sensitive data requirements.
%
%\end{Task}

 
 
%%\begin{Task}
%%\TaskTitle{Privacy vulnerability detection in Source Code from static analysis}
%%\TaskParticipant{YAG}{1}

%%\TaskStart{1}
%%\TaskEnd{36}
%%\TaskResults{%
%\ref{del:model1}
%%}
%%\TaskHeader{}
%%\tasklabel{task:PrivacyFromSAST}
%%In \theTask, we will improve the static analysis tool and its post-processing algorithms to extend vulnerability detection to distributed data specific vulnerabilities, with a particular focus on privacy and anonymization leaks. We will use as an input the description of the specific security and privacy vulnerabilities of distributed Machine learning to be identified in the task XX. We will integrate them in the static analysis detection and qualification algorithms. Programming languages to be scanned will be JAVA and C/C++.

%%The SAST and post processing algorithms will be developed to support design flaws in order to detect anonymization vulnerabilities and risks.

%%The vulnerability detection will include a business oriented semantics approach in order to support multilevel privacy and sensitive data requirements.

%% \end{Task}


\begin{WPDeliverables}
  \begin{compactitem}
\item \ref{del:bigdata1} (Month 11) : Software on Vulnerabilities Detection and Self-Healing for AI-Based Big Data Analytics on Private Clouds
 \item \ref{del:bigdata2} (Month 24) : Report on Vulnerabilities Detection and Self-Healing for AI-Based Big Data Analytics on Public Clouds 
 \item \ref{del:bigdata3} (Month 36) : Report on Vulnerabilities Detection and Self-Healing for AI-Based Big Data Analytics on Hybrid Clouds      
\end{compactitem}
\end{WPDeliverables}
\end{Workpackage}
