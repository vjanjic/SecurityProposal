\addtocounter{wpno}{1}
\begin{Workpackage}{\thewpno}
\wplabel{wp:securityBigData}
\WPTitle{\wpname{\thewpno}}
\WPStart{Month 1}
\WPParticipant{UOD}{26}
\WPParticipant{SCCH}{18}
\WPParticipant{SOPRA}{7}
\WPParticipant{USTAN}{2}
\WPParticipant{IBM}{2}
\WPParticipant{YAG}{2}

\begin{WPObjectives}
The objectives of \theWP{} are to:
\begin{compactitem}
\item Identify security risks in use of systems for distributed storage of data in large-scale AI-based big data analytics;
%, targetting both distributed NoSQL databases such as ScyllaDB and MongoDb and plain distributed filesystems such as Hadoop HDFS; 
\item Identify security risks in use of parallel processing frameworks (such as MapReduce) and high-level machine-learning libraries in large-scale AI-based big data analytics;
\item Develop novel mechanisms for evaluating and reducing privacy leakage in distributed AI;
%secure and privacy-preserving mechanisms for data release in machine learning based big data processing; \vjcomment{SCCH part}
\item Develop a novel framework for privacy-preserving transfer of knowledge extracted from private data sets to other parties;
%techniques for privacy-secured knowledge sharing in machine learning based AI systems; \vjcomment{SCCH part}
\item Exploit and adapt the self-healing mechanisms from WP2 to the problem of ensuring security and privacy of end-user big data analytics applications;
%Support semi-automatic repairing of the user code by integrating the self-healing mechanisms from WPXX into security and privacy-leakage diagnostics mechanisms for machine-learning based big data storage and analysis;
\end{compactitem}
\end{WPObjectives}

\begin{WPDescription}
The goal of this workpackage is to provide mechanisms for identifying security and privacy vulnerabilities in AI-based big data analytics, as well as to apply the self-healing techniques developed in WP2 to the problem of fixing vulnerabilities in such applications. As outlined in Section~\ref{sec:XX} and described in Figure~\ref{fig:xx}, a typical big data analytics application uses a number of different layers of abstraction, from generic libraries for distributed filesystems and databases at the lowest level, to specific, high-level machine-learning libraries at the highest level. We will exploit the technologies for the vulnerabilities identification and self-healing from WP2 to develop a framework that will be able to identify and repair security risks that appear in each different layer, as well as from the interaction between different layers. In task \ref{task:storage} we will focus on the data storage layer, identifying security vulnerabilities in the code that uses the chosen distributed databases and filesystems and, subsequently, repairing these vulnerabilities. The choice of libraries used will be driven by the uses cases and will include Cassandra DB and Azure Data Lake, as well as plain distributed filesystems such as HDFS. Task \ref{task:processing} focuses on the layers of pattern-based big data processing frameworks and machine-learning libraries. Examples of frameworks that will be considered here are MapReduce for generic big-data processing and Azure AI and Spark MLLib for machine learning. Task \ref{task:privacyLeakage} focuses on evaluating and reducing privacy-leakage in distributed machine learning, by investigating optimal noise-adding mechanisms for preserving privacy. Task \ref{task:knowledgeSharing} investigates knowledge sharing in distributed machine learning, developing techniques for privacy-preserving transfer of knowledge extracted from large data sets. Collectively, the diagnostics and repair mechanisms for security and privacy of machine learning data analytics from this work package will feed into the \TheProject{} methodology that will be developed in WP6.

Each task of this workpackage will proceed in three phases. In the first phase, we will focus on the security and privacy vulnerabilities characteristic to deployment of applications in private clouds. This will enable us to develop fundamental techniques in relatively safe setting which still, nevertheless, can expose vulnerabilities. The result of this phase for each task will be demonstrated in a software deliverable in~\ref{del:bigdata1}, providing initial versions of the tools, and reported in the accompanying report. In the second phase, we will extend the techniques to cover the issues in deploying the applications in public clouds. This setting exposes many more vulnerabilities than the private clouds. The results of this phase will be reported in~\ref{del:bigdata2}. In the third and final phase, we will adapt the developed techniques to deployment of applications in hybrid clouds, which may link private and public clouds or multiple public clouds. This presents us with even more complicated setting, where additional vulnerabilities arising from multiple layers of communication over domains with different level of protection can appear. The results of this phase will be reported in~\ref{del:bigdata3}.
\end{WPDescription}

\begin{Task}
\TaskTitle{Identifying and Repairing Vulnerabilities in Distributed Data Storage for AI-Based Big Data Analytics}
\TaskParticipant{UOD}{8}
\TaskParticipant{UCM}{5}
\TaskParticipant{SOPRA}{3}
\TaskParticipant{USTAN}{1}
\TaskParticipant{IBM}{1}
\TaskParticipant{YAG}{1}

\TaskStart{3}
\TaskEnd{33}
\TaskResults{%
\ref{del:bigdata1}
\ref{del:bigdata2}
\ref{del:bigdata3}
}
\TaskHeader{}
\tasklabel{task:storage}
In \theTask, we will define the methodology and conduct an analysis of vulnerabilities in usage of big data storage backends (such as NoSQL databases and distributed file systems such as HDFS).  We will select examples of NoSQL databases both constructed in C++ (or with C++ bindings for the end user code) and based on the JVM languages (Java and Scala for instance) and identify vulnerabilities that can arise from using them in distributed AI-based data analysis. For most of the part we will treat the databases and filesystems as black boxes, focusing on their usage rather than on their internals, but we will also, where feasible, identify vulnerabilities in the source code of the databases/filesystems bindings. This task will exploit the mechanisms for identification of security and privacy vulnerabilities from WP2 and adapt them to the specific issues arising in big data applications, identifying risks that appear both in the individual data storage agents in isolation, as well as from the interaction of these agents in distributed setting. In particular, side projects (such as language drivers) will be examined as these provide an attack vector that may be outside the open source projects control. We will 
also adapt the self-healing mechanisms from WP2 to the specific problem of big data storage considered in this task and provide input to the refactoring transformations and runtime adaptation mechanisms from tasks T2.4 and T2.5. 
 
\UODshort{} will contribute to this task with its expertise in storage for big-data analysis, selecting the appropriate databases/filesystems and applying the vulnerabilities detection and self-healing mechanisms developed in WP2 to them. \IBMshort{} and \YAGshort{} will provide consultancy for the use of their tools for source code analysis and symbolic execution. \UCMshort{} will provide expertise in C++ source code analysis to help with the vulnerability analysis of C++ storage software components.
 \end{Task}

 \begin{Task}
 \TaskTitle{Identifying and Repairing Vulnerabilities in Distributed Pattern-Based AI-Based Data Analytics}
 \TaskParticipant{UOD}{14}
 \TaskParticipant{UCM}{5}
\TaskParticipant{SOPRA}{4}
\TaskParticipant{USTAN}{1}
\TaskParticipant{IBM}{1}
\TaskParticipant{YAG}{1}
 \TaskStart{3}
 \TaskEnd{36}
 \TaskResults{%
 \ref{del:bigdata1}
 \ref{del:bigdata2}
 \ref{del:bigdata3}
 }
 \TaskHeader{}
 \tasklabel{task:processing}
 In \theTask, we will define the methodology and conduct analysis of vulnerabilities in usage of pattern-based frameworks for big data processing. This task will cover both the generic processing frameworks such as MapReduce and the higher-level specific machine-learning libraries such as Azure AI. These frameworks are usually built on top of distributed filesystems and databases and are presented to the end users in the form of a library that encapsulates data and computations distributions. They provide their own security challenges beyond those in data storage systems, as the location where the data is processed can be different to where it is stored, resulting in possibly very frequent data transfers across nodes (or even organisations). We will not tackle the security of the data whilst it is on the move (on the wire and the network stack) as that are the subject of other research areas.  The task will follow a similar pattern to that of \ref{task:storage} selecting candidates systems from those written in C++ or based on the JVM (Hadoop, Spark, Flink, Storm, Azure AI, Spark MLLib) exploiting source-code level analysis and using symbolic execution and runtime monitoring (WP2) to expose security vulnerabilities. In addition to that, we will also adapt the technologies for self-healing to the usage of big data processing framework, feeding into the refactoring and runtime transformations in WP2 as applied to the big data analysis problem.
 
\UODshort{} will lead this task, contributing with its expertise in parallel processing frameworks and big data analytics. \IBMshort{} and \YAGshort{} will provide consultancy for the use of their tools in discovering vulnerabilities in the targeted frameworks, as well as in application of the self-healing technologies. \UCM will perform vulnerability analysis of C++ processing software components.

\end{Task}
 
\begin{Task}
  \TaskTitle{Evaluation and Reduction in \textcolor{red}{Private} Data Leakage for Distributed Machine Learning Data Analytics}
  \TaskParticipant{SCCH}{9}
  \TaskParticipant{UOD}{2}
  
  \TaskStart{1}
  \TaskEnd{33}
  \TaskResults{%
  \ref{del:bigdata1}
   \ref{del:bigdata2}
   \ref{del:bigdata3}
  }
  \TaskHeader{}
  \tasklabel{task:privacyLeakage}
  In this task, we will develop mechanisms to both evaluate and reduce information leakage in distributed machine learning data analytics systems. The methods for evaluation of privacy leakage will be investigated in terms of relationship between sensitive data and released public data. Our approach is to employ a stochastic model for approximating the uncertain mapping between released noise added data and private data. The stochastic model facilitates a variational approximation of privacy-leakage in-terms of mutual information between sensitive private data and released public data. For reducing information leakage, we will develop optimal noise adding mechanisms for preserving privacy in distributed machine learning. We will derive analytically the noise distribution that maximises a given utility function or equivalently minimises a given data distortion function. Different use cases may demand different utility functions and thus optimal noise adding mechanism is derived for each utility function separately.
  
\SCCHshort{} will lead this task, contributing with its expertise in privacy of distributed machine learning. \UODshort{} will help with the adaptation of the developed techniques to large-scale big-data analytics. 

 \end{Task}

 \begin{Task}
  \TaskTitle{\textcolor{red}{Privacy-Preserving} Knowledge Sharing in Distributed AI}
  \TaskParticipant{SCCH}{9}
    \TaskParticipant{UOD}{2}

  \TaskStart{7}
  \TaskEnd{36}
  \TaskResults{%
    \ref{del:bigdata1}
   \ref{del:bigdata2}
   \ref{del:bigdata3}
  }
  \TaskHeader{}
  \tasklabel{task:knowledgeSharing}
  This task will develop an analytical framework to study and optimise the privacy-preserving transfer of knowledge extracted from a large set of labelled private data owned by a party to another party owning a few labelled data samples. The goal is to answer the question: how can a model be transferred from a source to a target domain while preserving privacy of both source and target domains? An information theoretic approach is considered to quantify transferability of knowledge from source to target domain in-terms of mutual information between source and target data. The privacy secured knowledge sharing framework facilitates development of transfer and multi-task machine learning algorithm while optimising the privacy-transferability tradeoff.
  
 \SCCHshort{} will lead this task, extending their existing work in privacy-preserving transfer of knowledge to the larger-scale distributed systems. \UODshort{} will contribute to the adaptation of this techniques for larger data sets present in big data analytics. 
 \end{Task}

 %%\begin{Task}
  %%\TaskTitle{Self-Healing in Distributed Data Processing Systems}
  %%\TaskParticipant{SCCH}{1}
  
  %%\TaskStart{1}
  %%\TaskEnd{36}
  %%\TaskResults{%
  %\ref{del:model1}
 %% }
  %%\TaskHeader{}
  %%\tasklabel{task:healing}
  %%In \theTask, we will integrate self-healing mechanisms developed in WPXX into the tools and techniques developed in this work package. Collectively, the diagnostics and repairs of security vulnerabilities developed in this work package will feed into the refactoring-based self-healing methodology from WP6. A sample use case from one of the technologies surveyed in \ref{task:storage}, \ref{task:processing}in  will be selected to demonstrate the application of self healing to that technology. 
 %%\end{Task}
 
 
% \begin{Task}
%  %\TaskTitle{Privacy-preserving Biometric Data}
%  \TaskTitle{Privacy-Preserving Biometric Data in Authentication for Big Data Systems}
%  \TaskParticipant{COGNI}{1}
%   \TaskParticipant{SCCH}{1}
%  
%  \TaskStart{1}
%  \TaskEnd{36}
%  \TaskResults{%
%  %\ref{del:model1}
%  }
%  \TaskHeader{}
%  \tasklabel{task:privacyBiometrics}
%  Bearing in mind that users' biometric data are irrevocable when exposed, it is very important to protect their privacy. In this task, new methods will be designed, developed and evaluated for preserving the privacy of the biometric data used for continuous authentication in WP5. Main aim of privacy-preserving biometric authentication is to enable users to verify themselves without disclosing raw and sensitive biometric information. For doing so, current privacy weaknesses and threats in biometric authentication will be analyzed, and novel privacy-preserving methods will be designed and developed to secure the implementation of biometric-based continuous authentication, such as, features' transformation, cancelable biometrics, pseudo-identities, etc.
% \end{Task}
% 
% 
%\begin{Task}
%\TaskTitle{Integration into \TheProject{} Front End User Interface}
%\TaskParticipant{YAG}{1}
%\TaskParticipant{SA}{1}
%\TaskStart{1}
%\TaskEnd{36}
%\TaskResults{%
%%\ref{del:model1}
%}
%\TaskHeader{}
%\tasklabel{task:PrivacyFromSAST}
%In \theTask, we will improve the static analysis tool and its post-processing algorithms to extend vulnerability detection to distributed data specific vulnerabilities, with a particular focus on privacy and anonymisation leaks. We will use as an input the description of the specific security and privacy vulnerabilities of distributed Machine learning to be identified in the task XX. We will integrate them in the static analysis detection and qualification algorithms. Programming languages to be scanned will be JAVA and C/C++.
%
%The SAST and post processing algorithms will be developed to support design flaws in order to detect anonymization vulnerabilities and risks.
%
%The vulnerability detection will include a business oriented semantics approach in order to support multilevel privacy and sensitive data requirements.
%
%\end{Task}

 
 
%%\begin{Task}
%%\TaskTitle{Privacy vulnerability detection in Source Code from static analysis}
%%\TaskParticipant{YAG}{1}

%%\TaskStart{1}
%%\TaskEnd{36}
%%\TaskResults{%
%\ref{del:model1}
%%}
%%\TaskHeader{}
%%\tasklabel{task:PrivacyFromSAST}
%%In \theTask, we will improve the static analysis tool and its post-processing algorithms to extend vulnerability detection to distributed data specific vulnerabilities, with a particular focus on privacy and anonymization leaks. We will use as an input the description of the specific security and privacy vulnerabilities of distributed Machine learning to be identified in the task XX. We will integrate them in the static analysis detection and qualification algorithms. Programming languages to be scanned will be JAVA and C/C++.

%%The SAST and post processing algorithms will be developed to support design flaws in order to detect anonymization vulnerabilities and risks.

%%The vulnerability detection will include a business oriented semantics approach in order to support multilevel privacy and sensitive data requirements.

%% \end{Task}


\begin{WPDeliverables}
  \begin{compactitem}
\item \ref{del:bigdata1} (Month 11) : Software on Vulnerabilities Detection and Self-Healing for AI-Based Big Data Analytics on Private Clouds
 \item \ref{del:bigdata2} (Month 24) : Report on Vulnerabilities Detection and Self-Healing for AI-Based Big Data Analytics on Public Clouds 
 \item \ref{del:bigdata3} (Month 36) : Report on Vulnerabilities Detection and Self-Healing for AI-Based Big Data Analytics on Hybrid Clouds      
\end{compactitem}
\end{WPDeliverables}
\end{Workpackage}
