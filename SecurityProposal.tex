 % !TeX encoding = UTF-8
\documentclass[a4paper,11pt]{article}

\newcommand{\project}[1]{\textbf{#1}\xspace}
\newcommand{\SECURITY}{\project{Security - Digital Fortress}}
\newcommand{\TheProject}{\SECURITY}

%\ifdefined\final
%\else
%\newcommand{\final}{}
%\fi

\input{preamble}
\input{participants}

\begin{document}
\pagenumbering{arabic} % for pageslts

\begin{titlepage}

\begin{center}
{\Huge \textsc{\TheProject}}
\end{center}

\begin{tabular}{lp{5in}r}
\textbf{Title of Proposal:} & \textbf{Intelligent Security and Privacy Management} & \\[4ex] 
\textbf{Date of preparation:} & \textbf{\today} & \comment{}{$
$Revision: 0.0$ $}\\[4ex]
\textbf{List of participants} && \\[1ex]


\end{tabular}

%% Participants Table
\newcounter{p}
\begin{center}
\begin{tabular}{|l|p{5in}|l|l|}\hline
\textbf{Participant no} & \textbf{Participant organisation name} & \textbf{Country}\\ \hline 
1 (Coordinator) & {\sc \longparticipant{1}} \hfill (\shortparticipant{1}) & \country{1}  \\ \hline
\forloop{p}{2}{\value{p} < \theparticipant}{%
\thep & {\sc \longparticipant{\thep}} \hfill  (\shortparticipant{\thep}) & \country{\thep}  \\ \hline}%
\theparticipant & {\sc \longparticipant{\theparticipant}} \hfill  (\shortparticipant{\theparticipant})& \country{\theparticipant}  \\ \hline
\end{tabular}\end{center}

\tableofcontents

\end{titlepage}

% \input{snags}
\newpage


\pagenumbering{roman}

% ---------------------------------------------------------------------------
%  Section 1: Excellence
% ---------------------------------------------------------------------------

\pagebreak

\pagenumbering{arabic}
\setcounter{page}{2}

%%\subsection{Contributions from the Partners}

%%\subsubsection{University of St Andrews - Security Contracts and Verification}
%%\begin{itemize}
%%    \item Formal specification of security contracts for pieces of code
%%    \item Refactoring to introduce secure code in the applications
%%    \item Formal verification of properties of the code with regard to security contracts
%%    \item Automated verification and reasoning (model checkers, constraint solvers and theorem provers, sometimes used in combination), logics including distributed temporal logics 
%%\end{itemize}

%%\subsubsection{Dundee - Security for Big Data}
%%\begin{itemize}
%%    \item Identifying and addressing security risks in large-scale distributed databases, both open- and closed-source ones.
%%    \item Identifying and analysing security risks in distributed parallel processing.
%%    \item Security for machine-learning based big data analysis
%%    \item Security contracts for distributed parallel code
%%    \item Dissemination
%%\end{itemize}

%%\subsubsection{IBM - Vulnerability Detection and Data Fabrication}
%%\begin{itemize}
%%\item  Vulnerability Detection
   
%%We propose to extend the ExpliSAT symbolic execution technology to discover known security vulnerability patterns in C/C++ code and combine it with the tailored fuzzing techniques in specific areas for the purpose of assisting the symbolic execution engine to consistently make progress and thus overcome a known "path explosion" problem of symbolic interpretation technologies.
 
%%\item Data Fabrication for ML
 
%%We have recently started to explore a new and very challenging direction of synthetic data fabrication for improving robustness of ML models and AI-based applications. It includes  use cases like data enrichment (missing or not sufficient training data), poisoned data (malicious data that is used as part of training data set to cause machine learning model malfunction) and evasion attack (malicious data that causes malfunction of a trained model).
%%Most of the recent research work in academia in this field is done based on "unstructured data" like images, video or text. We believe that for real industry use cases fubrication of structured data to test and improve robustness of ML models is more relevant. Our idea is to combine our rule-based (CSP-based) data fabrication approach with machine learning techniques to fabricate synthetic data for ML use cases.
 
%%\item Data Fabrication Platform
 
%%It is actually our current DFP product that is used in SERUMS. It can be mentioned and used in the new proposal in combination with any of the two "new" direction listed above.
%%\end{itemize}

%%\subsubsection{SCCH - Privacy-Preserving AI}
%%\begin{itemize}
%%    \item Informational Privacy
    
%%    To constrain the information leakage from a data set, we motivate an information theoretic approach to  privacy where privacy is quantified by the mutual information between sensitive private information and the released public data.
%%    \item Optimal Privacy Secured Data Release Mechanism 
    
%%    A data release mechanism aims to provide useful data available while simultaneously limiting any reveled sensitive information. The data perturbation approach uses a random noise adding mechanism to preserve privacy, however, results in distortion of useful data and thus utility of any subsequent machine learning and data analytic algorithm is adversely affected. We introduce a novel information theoretic approach for studying privacy-utility trade-off suitable for different data types (including high-dimensional data, signals, and images) and for the cases with unknown statistical distributions. 
    
%%    \item Privacy Secured Knowledge Sharing
    
%%   While sharing of knowledge extracted from a relatively large set of labelled data owned by an organization with another organization owning a few or no labelled data, it is intended that 
%%    \begin{itemize}
%%        \item privacy of data is preserved;
%%        \item transferability of knowledge from source to target domain is evaluated for the design and analysis of transfer learning algorithms;
%%        \item privacy-transferability trade-off is optimized. 
%%    \end{itemize} 
%%    We aim at the development of techniques and tools for the study and optimization of privacy and transferability aspects of machine learning based AI systems. 
%%\end{itemize}
%%\subsubsection{Cognitive UX - Intelligent User Authentication-as-a-Service}
%%\begin{itemize}
%%\item AI-driven and eye gaze-driven behavioral authentication (Topic C and D)

%%We can bring in multi-factor authentication solutions and more specifically AI-driven behavioral authentication by adding another layer of security in the authentication process to verify the end-users based on their interaction behavior, and/or their eye gaze behavior. For doing so, we currently utilize and can also bring in the project a range of eye-tracking and wearable technologies.

%%\item Authentication-as-a-Service (Topic C and D)
%%We are interested to conduct research and extend our product (Cognitive Authentication), which offers an integrated user authentication solution that allows service providers to set their own password policies, authentication types, get insights from end-users' interaction data, etc.

%%\item User experience and usability evaluations and activities
%%\item System integration and testing
%%\item Dissemination activities on Usable Security, HCI, Authentication, Eye-tracking, and Intelligent User Interfaces
%%\end{itemize}

%%\subsubsection{Sopra-Steria Limited}

%%As a commercial partner we want to start investigation into the following areas:
%%\begin{itemize}
%%    \item Finance (open banking for CMA9) as data source for a universal banking solution that supports a secure banking interaction with appropriate trust and privacy as expected. Want to test existing and future code for security vulnerabilities.
    
%%    \item Space-based Open Internet capabilities with low Earth orbit satellites using an open meshed network for communication. Investigate how Delay/Disruption Tolerant Networking (DTN) and Solar System Internet (SSI) will impact our communication security and enable citizen services like social care and healthcare. Want to include security by design into the code and indirectly the deployed systems.
    
%%    \item Distributed healthcare (IoT) to support remote healthcare and intervention via open network technology. Test and repair the IoT code for vulnerability at the edge of the network.
    
%%    \item Sovereign Identity Clearance House using a Self-sovereign identity (SSI) token for essential communication as a citizen with the citizen's digital twin.
%%\end{itemize}

%%We propose three business areas to research the develop of automated tools for validating the security and privacy of data processing code, underlying systems' code and exposed online services used to provision these services to citizens. We want to introduce a practical solution for zero-trust architecture of the system while preserving the ever-increasing use of open and common internet-based communication channels between businesses and citizens without losing the trust and security that each citizen wants.

%%Sopra-Steria Limited will supply an insight into the real-world case studies that we could use to prove the research is achieving the proposed outcomes.

%%We also hold various advance technical capability that can be used to support the general project to ensure data engineering, machine learning and data science skills are available for use by the projects research life-cycle.

%%\subsubsection{University Carlos III of Madrid}

%%\begin{itemize}
%%\item C++ standardization process with 12 years of membership in the ISO C++ standards committee.
%%\item Integration in the C++ programming language of contracts in the form of preconditions, post conditions, invariants, \ldots
%%\item Identification and avoidance of software vulnerabilities (security and safety) derived from programming language features 
%%\item Patterns for parallel programming.
%%\end{itemize}

%%\pagebreak


\section{Excellence}
"The world's most valuable resource is no longer oil, but data" is the now world-famous quote from The Economist that highlights the importance of data analytics in the modern world. Dealing with and making sense of the vast amount of data available to us through rich and diverse %the variety of 
sources is an imperative which made data analysts and statisticians the most desirable professions in 2019\footnote{Quote for data analysts and statisticians being the best professions in 2019}. Modern data analysis is necessarily distributed in nature and, for most of the part, based on advanced AI techniques such as deep learning. At the same time, digitisation of the modern world presents completely new challenges for cybersecurity. A highly-distributed world of AI-based big data analytics means there are plenty more possibilities from vulnerabilities, coming both from the way big data is stored (usually in flat files or distributed databases) and also in the way it is processed, with multiple distributed agents interacting and exchanging potentially sensitive information. Security mechanisms that protect the sensitive data in this settings are still not advanced enough to provide enough trust in the whole data analytics process. \emph{The main goal of the \TheProject{} project is to significantly increase the trust in modern data analytics systems by combining formal and practical aspects of code development and analysis.} Our methodology will be based on formally specified, machine readable and verifiable \emph{security contracts} that will specify the security aspects of the sensitive parts of distributed code.

\jbcomment{There is a slight disconnect above between data and code (that processes and/or generates data) - needs to be made clearer, as we address both. Code is only mentioned in the final two sentences...}

%The emergence of big data, supported by distributed machine-learning based data analytics tools and techniques, presents new and unforeseen challenges for data security and privacy. Security vulnerabilities can come both from the individual components of the distributed data-analytics systems, as well as from the undeterministic way in which these components may interact. The Digital Fortress project aims to develop a novel methodology and the associated tool-chain for implementing secure distributed data processing applications. We will tackle the problem both from theoretical and practical aspect, implementing novel formally-verifiable security contracts that will specify security properties of the distributed code, and supporting this contracts with a novel code refactoring tools and dynamic vulnerability detection techniques. The focus on the project will be on machine-learning based analytics techniques, addressing the issues that come from both storage and processing of the data and learning models. As an additional layer of security, we will implement novel integrated behaviour-based user authentication schemes.


\subsection{Aims and Objectives}
\label{sect:objectives}

\eucommentary{\emph{Describe the specific objectives for the project1, which should be clear, measurable, realistic and achievable within the duration of the project. Objectives should be consistent with the expected exploitation and impact of the project (see section 2).}}


The specific \emph{aims} and \emph{objectives} of the \TheProject{} project are:

\begin{description}
\item[Aim 1:] To produce novel methods for formal specification and verification of security properties of
  distributed machine-learning based data analytics systems, addressing security and privacy of both data storage and data processing;

\item[Aim 2:] To build on the existing and develop new efficient techniques for identifying generic code patterns that
  represent known security vulnerabilities and data leakages in the distributed AI-based systems and to develop novel techniques for  
  repairing of the identified vulnerabilities and leakages;

\item[Aim 3:] To build additional security layers on top of the existing systems, based on novel, intelligent and secure authentication methods;

\item[Aim 4:] To integrate the \TheProject{} tools and techniques into a coherent self-healing methodology for establishing
  security and privacy properties of the code and repairing any identified vulnerabilities and leakages, targeting both 
  existing distributed machine-learning based data analytics code and new provably-secure code;

\item[Aim 5:]  To demonstrate the applicability of the \TheProject{} tools and
 methodology in building secure real-world application from the medical, aerospace and
 banking domains and to promote their long-term uptake by building a sustainable user community,
 covering both experts in security and normal application developers;

\end{description}

The corresponding concrete \emph{objectives} are: 
\begin{description}

%\item[Objective 1:] To develop a novel concept of machine-readable \emph{security contracts}
%  that will be used to specify precisely security properties for parts of the C++ code, and to develop methods
%  for their formal specification and verification in the new and existing C/C++ code. \emph{This fulfils part of \textbf{Aim 1} and \textbf{Aim 4}}.
%  \comment{CB: It's not clear to me what machine-readable actually means, as, arguably, any arbitrary stream of bytes in a file is machine readable :D I think this needs clarified. There's a worry here that this is the same as what we have done on TeamPlay, where we also developed proofs, contracts and certificates for security, energy and time. What is the novelty here? There should probably be some tie-in, perhaps, to the work done on TeamPlay, CSL, for instance, or the proof system developed there. I think this needs to tie in with the refactoring tooling. One novel approach here is the refactorings... perhaps new refactorings that transform the application in such a way that it can meet a user-defined security specification or contract?  }
%  \comment{JB: If we are treating security contracts as a notion at several levels of abstraction and we can go between them, this would potentially be quite different from TeamPlay? It should not just be at the code level... }
 
\item[Objective 1:] To develop a novel concept of \emph{secure} patterns for distributed machine-learning based data analytics to support these
patterns with strictly-defined and formally-verifiable multi-level \emph{security contracts}, raising the level of abstraction
for developing secure distributed applications and providing formal guarantees about their security properties; 
\emph{This fulfils part of \textbf{Aim 1}}. 
%  \item[Objective 1:] To develop a novel techniques for verification of security properties of the application code,
%  specified in a formal way by machine-readable \emph{security contracts}, giving strict guarantees about
%  the safety of runtime behaviour of undeterministic large-scale distributed data analytics; \emph{This fulfils part of
%    \textbf{Aim 1}}.

\item[Objective 2:] To develop novel techniques for identifying security and privacy risks, based on symbolic execution supported by fuzzy logic and on code analysis, both in storage of big data used for training of machine-learning models and in pattern-based distributed data analytics based on machine learning, guiding the verification of security properties in large-scale distributed settings. \emph{This fulfils parts of \textbf{Aim 1}, \textbf{Aim 2} and \textbf{Aim 4}}.
  
\item[Objective 3:] To develop novel \emph{self-healing} techniques, based on XX and noise-adding for data privacy, for semi-automatic repairing of the code for distributed machine-learning based data analytics in which security vulnerabilities and/or private data leakages have been identified.\emph{This fulfils part of \textbf{Aim 2} and \textbf{Aim 4}}.

\item[Objective 4:] To build on the existing and develop new security \emph{coding standards} for C++, providing guidance to developing new secure distributed data analytics applications. \emph{This fulfils parts of \textbf{Aim 1}, \textbf{Aim 2} and \textbf{Aim 4}}.

\item[Objective 5:] To augment the existing security layer of distributed data analytics application with AI-driven behavioural authentication models, implementing Authentication-as-a-Service (AAAS) technology. \emph{This fulfils parts of \textbf{Aim 3} and \textbf{Aim 4}}.

\item[Objective 6:] To develop a novel methodology, based on security contracts, vulnerability detection/mitigation,
  privacy preserving and secure authentication, and supported by semi-automated code refactoring techniques for
  increasing security of the existing and developing secure new distributed data-analytics algorithms. \emph{This fulfils
    part of \textbf{Aim 4}}.

\item[Objective 7:] To demonstrate that the \TheProject{} tools and techniques allows improved security and reduced
  information leakage in distributed learning-based data analytics code, using a variety of real-world security-sensitive
  use cases from healthcare, banking and aerosepace application domains. \emph{This fulfils part of \textbf{Aim 5}};

\item[Objective 8:] To build a sustainable user community involving a variety of stakeholders that will ensure the long-term
  uptake, development and commercial success of the tools and techniques developed over the course of the \TheProject{}
  project. \emph{This fulfils part of \textbf{Aim 5}}.

\end{description}

%\subsubsection{Provisional list of workpackages:}
%\begin{itemize}
%\item WP2: Specification and Verification of Security Contracts for Distributed Data Analytics (USTAN)
%\item WP3: Security and Privacy of Big Data Storage and AI-based Processing (UOD/SCCH)
%\item WP4: Vulnerability Detection (IBM)
%\item WP5: AI-Driven Behavioural Authentication (COGNITIVE UX)
%\item WP6: Refactoring-Based Methodology for Secure Application Development (USTAN)
%\item WP7: Use cases (SOPRA)
%\item WP8: Dissemination and Exploitation (UOD)
%\end{itemize}

\label{sect:objs-detailed}

\TOWRITE{UOD and USTAN}{This needs to be done after
the objectives are defined above   We need about 1-2 paragraphs
per objective, just to flesh it out.}

\subsubsection{Detailed Description of the Objectives}

\subsubsection*{Objective 1: Secure Patterns for Distributed Data Processing}
%subsubsecton*{Security Contracts for Formal Specification of Security Properties}
\vspace{-6pt}
Parallel patterns are a well-established abstraction for programming complex parallel and distributed systems, adopted by a number of major IT companies such as Intel and Microsoft. They allow structuring of the end-user code at a high level and make formal reasoning about the code much easier, as they can provide additional information, such as a semantics of the expected behaviour of the about the application with respect to the underlying formal models. On the other hand, a formal treatment of the security properties of the code requires a multilayer approach, where a high-level human-understandable description of the properties of the code is transformed into precise, machine-readable description that can be used for formal reasoning. In the \TheProject{} project, we will develop novel \emph{secure} patterns for distributed large-scale data processing that will, in addition to performance considerations, give strict guarantees about their security properties. This will be achieved by supporting these patterns with both \emph{security certificates}, which will describe in a natural way the properties of the code, and the associated lower-level, machine-readable \emph{security contracts} that will be appropriate for automated reasoning. We will also develop mechanisms to automatically prove the properties specified in the security contracts for C++ and Java applications, and also mechanisms to translate security certificates into security contracts and vice versa. The end users will then be able to choose a security-certified patterns suitable for their data analytics tasks, and will be presented with guaranteed security properties of the resulting code in an easily-understandable way. 
%Formal treatment of the security properties of the code requires a multilayer approach. On one hand, end users want to see a description of the security properties in a clear, high-level and human-understandable way. On the other hand, formal reasoning, including automatic proving of the properties, requires significantly lower-level approach. The language for formal reasoning needs to be concise and machine-readable. This necessitates different approach to describing properties at different levels. In the \TheProject{} project, we will develop a strict and precise notion of security properties at different levels of abstraction. We will develop a concept of \emph{security certificates}, which will describe in natural way the properties of the code. We will also develop \emph{security contracts}, which will be specified in low-level, machine-readable way appropriate for automated reasoning. We will also develop mechanisms to automatically prove the properties specified in the security contracts for pieces of C++ and Java code and also mechanisms to translate security certificates into security contracts and vice versa. The end users will then be able to specify the required properties using high-level language, and these properties will be automatically checked by lower-level mechanisms.
%\cbcomment{See above comments about similarities with teamplay. CSL is a source-level annotation language that allows the programmer to describe security propoerties in a clear high-level human-understandable way with certificates. Idris provides the proofs and formal reasoning and contracts. I'm also not keen on multiple languages. Is there a reason for both C++ and Java?}


\subsubsection*{Objective 2: Identification of Security and Privacy Risks in Machine-Learning Based Data Analytics}
\vspace{-6pt}

With the emergence of big data, many different technologies for both storing and processing this data have emerged. On the storage side, most commonly used tools are distributed databases and flat filesystems. While providing good reliability via fault tolerance, the security mechanisms used by databases and filesystems are still very basic, making them a security liability. On the data processing side, machine-learning has emerged as the prominent set of methods for making sense of and analysing the vast amount of data available. Distributed machine learning algorithms, however, present a whole set of new challenges, both in terms of security and in terms of privacy. Security risks and privacy leaks can come both from training the models and from using the built models, as well as from the models themselves. In the \TheProject{} project, we will develop methods to identify known and unknown security risks coming both from the individual agents invovled in the process of storing and analysing big data, and from the interaction between different agents in distributed settings. For identifying security risks, we will use both static source code analysis and dynamic \emph{symbolic execution}, where a program is executed abstractly, covering multiple possible inputs of the program that share a particular execution path through the code. We will also develop methods based on stochastic modelling for identifying and quantifying leakage of private information coming from building and applying of distributed machine learning models.

\subsubsection*{Self-Healing Mechanisms for Repairing Vulnerabilities and Reducing Data Leakage}
While identifying security risks and privacy leaks is critical for security of distributed data analytics, it is equally important to develop methods for \emph{repairing} the identified risks and leaks. These methods should be as much transparent to the end user as is practically possible, not requiring them to be security experts while still allowing them to develop efficient and secure code. At the same time, the end user should be aware of the changes made to the code, allowing them to intervene and apply their domain-specific knowledge to the code transformation that aim to improve security and privacy. In the \TheProject{}, we will develop novel \emph{self-healing} techniques for semi-automatic transformation of the code to eliminate security risks and privacy leaks. Privacy leaks will be addressed using optimal noise-adding mechanisms while security risks will be repaired using various code transformation techniques. We will also address the problem of knowledge transfer from the data owned by one party to another party while still respecting data privacy. All the code transformation will be supported by software refactoring, guiding the user step-by-step in the process of transforming their code and allowing its input at any stage.


%% We will move part of this to the background work & advancement beyond STOA
%%\subsubsection*{Objective 3: Symbolic Execution for Discovering Security Vulnerabilities}
%%\vspace{-6pt}
%\vjcomment{IBM to write this part}
%%Particular execution path through the code. The execution treats these inputs symbolically, “returning” a result that is expressed in terms of symbolic constants that represent those input values.
%%A known advantage of the symbolic execution technique is its ability to avoid giving false warnings; any error found by symbolic execution represents a real, %%feasible path through the program, and can be witnessed with a test case that illustrates the error.
%%In the \TheProject{} project, we will extend the ExpliSAT symbolic execution technology of IBM to discover known security vulnerability patterns in C/C++code. Moreover, to avoid known limitations of the symbolic execution approach (e.g. path explosion, memory growth, etc.), we will develop a technology that leverages the combination of white box fuzzing and symbolic execution to find exploitable bugs. The idea is to perform symbolic execution as the main technique to discover vulnerabilities combined with tailored fuzzing techniques in specific small areas for the purpose of assisting the symbolic execution engine to consistently make progress.

%% VJ : Also move this to the background & advancement beyond STOA
%\subsubsection*{Objective 4: Identifying and Controlling Privacy-Leakage in Distributed Machine Learning}
%\vspace{-6pt}
%The datasets containing sensitive information can't be publicly shared as a privacy-risk posed by several types of attacks exists. A novel information theoretic framework is introduced for privacy-preserving distributed machine learning such that privacy-leakage is quantified by the mutual information between sensitive data and released data. At the core of privacy-preserving framework lies a stochastic model approximating the uncertain mapping between released noise added data and private data such that the model is employed for variational approximation of informational privacy. The suggested privacy-preserving framework consists of three components: 1) Optimal Noise Adding Mechanism; 2) Modeling of Uncertain Mapping Between Released Noise Added Data and Private Data; and 3) Variational Approximation of Information Privacy. 
%There is an interest in sharing knowledge extracted from the data owned by a party with another party while simultaneously preserving the privacy of private data of both parties. An analytical framework is introduced to study and optimize the privacy-preserving transfer of knowledge extracted from a large set of labelled private data owned by a party to another party owning a few labelled data samples. An information theoretic approach is considered to quantify transferability of knwoledge from source to target domain in-terms of mutual information between source and target data. The privacy secured knowledge sharing framework facilitates development of transfer and multi-task machine learning algorithm while optimizing the privacy-transferability tradeoff.                

\subsubsection*{Objective 4: Security Coding Standards}



\subsubsection*{Objective 5: Intelligent User Authentication-as-a-Service}
\vspace{-6pt}

User authentication is a cornerstone of security in modern computing systems. Two important quality dimensions of an effective authentication system relate to its \textit{security} and \textit{usability aspects}. The security level determines its strength against adversary attacks, whereas usability levels are commonly determined by task execution efficiency and effectiveness. However, user authentication has become a complex and time-consuming task for any organization today due to constant cybersecurity threats and strict regulatory and new directives such as PSD2 that require strong, multi-factor authentication solutions. At the same time, end-users demand a seamless authentication experience. In the \TheProject{} project, we will develop an Authentication-as-a-Service technology allowing developers to easily integrate, deploy and manage their preferred authentication methods depending on custom requirements and policies. From the users’ point of view, the authentication technology will provide a fluid authentication experience based on state-of-the-art authentication methods such as usable, single-touch user approvals, as well as intelligent and continuous authentication based on users' interaction and eye gaze data analysis. In addition, we will develop data analytics and reporting services aiming to provide intelligent insights from user interactions and eye gaze behavior data allowing developers to deliver personalized security experience and thus increase user acceptance and trust.

\subsubsection*{Objective 6: Methodology for Deveopment of Secure Applications}
\vspace{-6pt}

It will be necessary to bridge the gap between the relatively low-level techniques for verification of the security properties of the code, with the focus on machine-learning based analytics of big data and including the techniques for identification of vulnerabilities and high-level of abstraction that the end users want to have the code and security properties presented. In the \TheProject{}, we will build onto our previous work on \emph{software refactoring} as a part of tool-chains for software engineering of the parallel and distributed applications and develop a refactoring-based programming methodology for developing secure applications. Our methodology will integrate various tools developed over the course of the project, including analysis and automated proving technqiues, security vulnerabilities detection tools and analysis of security and privacy of machine learning models, into a coherent tool-chain that will be supported by the code refactoring technology. In this way, the programmer will be fully included in the development loop, having full control over the incremental transformations that will make their code more secure.

\cbcomment{I wonder if the refactoring is downplayed too much. If the proposal focused more on the idea of the end-user, refactoring becomes vital to that. Also the idea of refactorings to transform programs to make them more secure. Perhaps meeting the specifications/contracts that are described in Objective 1. Also, maybe the refactoring use some kind of security pattern in the rewriting, which would be a novelty. }

\subsubsection*{Objective 7: Demonstrating \TheProject{} Tools and Technologies on Real-World Use Cases}
%  from automotive, machine learning and IoT domains.}
\vspace{-6pt}
We will validate the \TheProject{} methodology for developing secure applications, together with the associated tools and technologies, on realistic use cases taken from our partners at XX, XX and XX.
%In particular, the \TheProject{} technologies will be applied to the development
%of a \emph{completely new} distributed data analytics application by XX.
Consequently, all of the technologies that will be developed over the course of the \TheProject{} project will be extensively tested in a realistic setting, enabling us to identify new issues and security risks as they arise, and guiding our roadmap for future technological adoption. The use cases will demonstrate that we are able to deal with large-scale distributed data analytic in secure and privacy-preserving way, processing large volumes of data with increased trust in the safety of the operations.At the same time, by using user-guided refactoring-driven methodology, supported by a tool chain, we will reducing the cost of development, deployment and maintenance of the distributed systems.
%Thanks to our \emph{data fabrication} technology, we will be able to test parts of the system
%and a system as a whole on large volumes of synthetic, but realistic,
%data, both during development and during deployment.

\subsubsection*{Objective 8: Long-Term Uptake of \TheProject{} Technologies} 
\vspace{-7pt}
\TheProject{} aims to ensure long-term uptake of the technologies that it will develop by engaging with relevant user, developer and adopter communities, by following an Open Science approach, and by providing a roadmap for the future development and exploitation of the \TheProject{} technologies. We have built in specific user community building activities, including workshops, tutorials, webinars and training sessions, that will serve to actively promote the use of the \TheProject{} technologies. Whenever feasible, our software and results will be made publicly available in open source/open data repositories. We will actively engage with potential users from the chosen domains through exhibitions, demonstrations and presentations at existing events and conferences such as XX, through the annual EU ICT conference, through exploiting our excellent high-level contacts with the XX. Innovation Centres and other relevant organisations, through contacts with national government agencies, including XX and through other relevant expert networks.

\pagebreak
\subsection{Relation to the Work programme}

\TheProject{} directly addresses the challenge that is posted by \textbf{H2020-SU-DS-2020}. By exploiting the partners' experitse in security and distributed data analytics based on machine learning and by integrating the developed solutions into a semi-automated refactoring-based software development methodology, we aim to \textbf{integrate state-of-the-art approaches for security and privacy management in a holistic and dynamic way} while \textbf{relying on Artificial Intelligence and automation and reducing the level of human intervention necessary}. Our techniques for discovery and management of security and related to the storge of big data (e.g.~in distributed databases and file systems) will address the problem of \textbf{storage and processing of data in different interconnected places} while the focus on its large-scale machine-learning based distributed processing will allow the end users to \textbf{constantly forecast, monitor and update the security of their ICT systems}. Collectively, detecting security risks in data storage and processing will allow \textbf{monitoring and mitigation of security risks, including those related to data and algorithms}. Our inherent focus on distributed systems, with a particular focus on privacy and security of machine learning frameworks and models, both while they are trained and while they are used, will improve \textbf{collaboration and sharing of information related to security and privacy management}. 

The specific focus of \TheProject{} is on on part \textbf{c) Advanced security and privacy solutions for end users or software developers} part of the proposal call. Within that, our main aim is to \textbf{develop automated tools for checking the security and privacy of data, systems, online services and applications}. By building on the well-established software engineering concept of \emph{patterns} for data processing, and by supporting the techniques that will be developed over the course of the project by semi-automated tools for analysing and transforming the user code, we will \textbf{support end users or software developers (possibly including developers of AI solutions) in their efforts to select, use and create trustworthy digital services}. By evaluating the \TheProject{} techniques on real-world applications coming from aerospace, banking and healthcare domains, we will address \textbf{real application cases}. Refactoring-based programming methodology will contribute to \textbf{automatic code generation}. Supporting the secure patterns for distributed data processing by the techniques for the formal specification and verification of their security properties, we are contributing to creation of \textbf{trustworthy data boxes}, \textbf{certification and assurance} and \textbf{cyber insurance}.

As described in Section~\ref{sec:impact} (Expected Impacts), \TheProject{} will meet all the expected impacts that have been defined for \textbf{H2020=SU-DS-2020}, developing appropriate metrics to measure its impact on
\begin{itemize}
\item reduced number and impact of cybersecurity incidents;
\item efficient and low-cost implementation of the NIS Directive and General Data Protection Regulation;
\item effective and timely co-operation and information sharing between and within organisations as well as self-recovery;
availability of comprehensive, resource-efficient, and flexible security analytics and threat intelligence, keeping pace with new vulnerabilities and threats;
\item availability of advanced tools and services to the CERTs/CSIRTs and networks of CERTs/CSIRTs;
\item an EU industry better prepared for the threats to IoT, ICS (Industrial Control Systems), AI and other systems;
\item self–recovering, interoperable, scalable, dynamic privacy-respecting identity management schemes.
\item availability of better standardisation and automated assessment frameworks for secure networks and systems, allowing better-informed investment decisions related to security and privacy;
\item availability and widespread adoption of distributed, enhanced trust management schemes including people and smart objects;
\item availability of user-friendly and trustworthy on-line products, services and business;
better preparedness against attacks on AI-based products and systems;
\item a stronger, more innovative and more competitive EU cybersecurity industry, thus reducing dependence on technology imports;
\item a more competitive offering of secure products and services by European providers in the Digital Single Market.
\end{itemize}
\eucommentary{Indicate the work programme topic to which your proposal relates, and
 explain how your proposal addresses the specific challenge and scope
 of that topic, as set out in the work programme.}

{\color{blue}{
    Specific Challenge:
    
 In order to minimise security risks, ICT systems need to integrate state-of-the-art approaches for security and privacy management in a holistic and dynamic way. Organisations must constantly forecast, monitor and update the security of their ICT systems, relying as appropriate on Artificial Intelligence and automation, and reducing the level of human intervention necessary.

Security threats to complex ICT infrastructures, which are multi-tier and interconnected, computing architectures, can have multi-faceted and cascading effects. Addressing such threats requires organisations to collaborate and seamlessly share information related to security and privacy management.

The increasing prevalence and sophistication of the Internet of Things (IoT) and Artificial Intelligence (AI) broadens the attack surface and the risk of propagation. This calls for tools to automatically monitor and mitigate security risks, including those related to data and algorithms. Moreover, storage and processing of data in different interconnected places may increase the dependency on trusted third parties to coordinate transactions.

Advanced security and privacy management approaches include designing,
developing and testing: (i) security/privacy management systems based
on AI, including highly-automated analysis tools, and deceptive
technology and counter-evasion techniques without necessary human
involvement; (ii) AI-based static, dynamic and behaviour-based attack
detection, information-hiding, deceptive and self-healing techniques;
(iii) immersive and highly realistic, pattern-driven modelling and
simulation tools, supporting computer-aided security design and
evaluation, cybersecurity/privacy training and testing; and (iv)
real-time, dynamic, accountable and secure trust, identity and access
management in order to ensure secure and privacy-enabling
interoperability of devices and systems.

\begin{itemize}
\item[(c)]: Advanced security and privacy solutions for end users or software developers

Proposals should develop automated tools for checking the security and privacy of data, systems, online services and applications, in view to support end users or software developers (possibly including developers of AI solutions) in their efforts to select, use and create trustworthy digital services. Proposals should address real application cases and at least one of the following services: automatic code generation, code and data auditing, trustworthy data boxes, forensics, certification and assurance, cyber insurance, cyber and AI ethics, and penetration testing.

The outcome of the proposal is expected to lead to development up to Technology Readiness level (TRL) 6; please see Annex G of the General Annexes.

The Commission considers that proposals requesting a contribution from the EU of between EUR 2 and 5 million would allow this specific challenge to be addressed appropriately. Nonetheless, this does not preclude submission and selection of proposals requesting other amounts.

Type of Action: Research and Innovation Action

\item[(d)]: Distributed trust management and digital identity solutions

With particular consideration to IoT contexts, applicants should propose and test/pilot innovative approaches addressing both of the following points: (i) distributed, dynamic and automated trust management and recovery solutions; and (ii) developing novel approaches to managing the identity of persons and/or objects, including self-encryption/decryption schemes with recovery ability. Proposals should address real application cases.

The outcome of the proposal is expected to lead to development up to Technology Readiness level (TRL) 5-6; please see Annex G of the General Annexes.

The Commission considers that proposals requesting a contribution from the EU of between EUR 3 and 6 million would allow this area to be addressed appropriately. Nonetheless, this does not preclude submission and selection of proposals requesting other amounts.

Type of Action: Research and Innovation Action
\end{itemize}

}}


\subsection{Concept and Approach}

\eucommentary{Describe and explain the overall concept underpinning the project. Describe the main ideas, models or assumptions involved. Identify any trans-disciplinary considerations;}

%% Why do we need distributed data analytics?
In modern world, data is everywhere around us. With the emergence of Internet-of-Things, the amount of data available from a variety of sources is increasing by orders of magnitude every XX years. It is estimated that in the year XX, there will be XX petabytes of data collected from various sources every day. Such a vast amount of data gives many opportunities for smarter decision making and improved services in many areas of industry. Because of this, AI-based data analytics have become one of the most prominent areas of computer science, with a variety of systems that support complex analytics techniques on raw data (e.g.~Spark ML, XX and XX). Many of these systems are \emph{parallel and distributed} by nature. The requirement for parallelism comes from the fact that performing data analytics on large volumes of data is usually computationally very expensive, and properly parallelising the analytics can significantly reduce response time and deliver results much faster. The disributed aspect of data analytics comes from both distributed nature of the soruces of data, and by the fact that distributed systems (such as clouds) offer much more computational power at relatively cheap price than even the high-end local highly-performance systems. 

Distributed data analytics, however, present unforeseen security challenges for the users. In the distributed world, there are far more potential targets for cyber attacks. All of the potential security issues for local sites are present, as well as many additional risks that come from interaction of processing agents in the distributed world and movement of data between different distributed nodes. The security systems currently used in the big data analytics systems are fairly basic. Moreover, \emph{formal} treatment of security properties of the code is currently lacking. There are very little systems that can guarantee security properties of the code and that can, moreover, automatically and strictly check that the end user code conforms to the security specification or one of the desired security standards. Lack of guarantees about security properties, coupled with very complex scheme of interaction betweeen data processing and data storage agents in distributed world makes establishing security of distributed data analytics one of the most complex and overlooked issues currently. The \TheProject{} project aims to tackle this crucial issue of security of AI-driven big data analytics systems.



\vspace{-6pt}

\subsubsection{Challenges for Security and Privacy}
% massively-parallel heterogeneous systems}

Ensuring security of distributed AI-driven big data analytics presents a number of challenges:

\begin{itemize}
\item \textbf{Security of Big Data Storage Systems.} Large volumes of raw data on which data analytics is performed are usually stored in distributed NoSQL databases (such as Cassandra) or simply as flat files in some form of distributed file system (such as Hadoop's HDFS). Primary issues in the design of such system are robustness, scalability, fault tolerance and the speed of access for reading. Due to that, security mechanisms that distributed databases and filesystems use are very rudimentary. In addition to the problem of security of data stored in the database, distirbuted data analytics presents additional security issues which occur when the data is on the move between different sites. We must ensure both that the data is safely stored in databases and that the movement of data does not expose potential security and/or privacy vulnerabilities that can be exploited in cyber attacks.
\item \textbf{Security of Pattern-Based Distributed Parallel Processing.} In order to analyse large volumes of data and extract useful information and knowledge from it, it is essential to use parallel processing. This is not only in order to get the results in reasonable time - requirement for parallel processing comes from the way in which big data is stored. The space requirements for large data sets usually surpass the storage capabilities of individual machines and, therefore, this data has to be distributed. Furthermore, bringing all data to one place for analysis is usually prohibitively expensive, even when it is theoretically possible. Therefore, it is standard to have different processing agents on different distributed nodes which work together in analysing large data sets. Parallel patterns, such as Google's MapReduce that is used in Hadoop, provide high-level framework for data analytics where parallelism is provided for free. However, for the same reasons as with data storage, these systems potentially expose many additional security risks, coming from their interaction over networks as well as from the individual processing agents. We must ensure that distributed paralell processing used in Ai-based data analytics does not leak sensitive information from the data it processes to the malicious users.
\item    
\item 
\end{itemize}


The challenges identified above require a new and radical
approach that tackles these issues in a coherent and
holistic way. 

\subsubsection{Achieving The \TheProject{} Vision}


\subsubsection*{Key assumptions}

\vjcomment{This may not be necessary.}

\TheProject{} makes a number of fundamental assumptions that will be tested and verified in the course of the project,
and which form the basis for a register of technical risk.  The most significant assumptions are:

\begin{enumerate}[{A}1)]
\item XX
\end{enumerate}

\subsubsection*{Transdisciplinary concerns}
 \vjcomment{Only if relevant}


\subsubsection{Positioning of the project}
\eucommentary{Describe the positioning of the project e.g. where it is situated in the spectrum from 'idea to application', or from 'lab to market'. Refer to Technology Readiness Levels where relevant.}

In line with the expectations of the XX call, \TheProject{} aims
to achieve overall Technology Readiness Level (TRL) 5-6 (``technology
validated in relevant environment (industrially relevant environment in
the case of key enabling technologies)'').

\begin{center}
  \begin{tabular}{|p{4.9in}|l|l|}
    \hline
    \textbf{Key Enabling Technology} & \textbf{Current TRL} & \textbf{Final TRL} \\
    \hline
     &  & \\
    \hline XX & TRL 5 & TRL 6 \\  
    \hline
  \end{tabular}
\end{center}

\noindent
The specific advances that will be made are described in more detail in Section~\ref{sec:novelty} (page~\pageref{sec:novelty}).


\subsubsection{Linked research and innovation activities}
\label{projects}

\eucommentary{Describe any national or international research and innovation activities which will be linked with the project, especially where the outputs from these will feed into the project;}

\vspace{-8pt}
\paragraph{\teamplay (ICT-779882).}
The TeamPlay project aims to develop new, formally-motivated, techniques that will allow execution time, energy usage, security, and other important non-functional properties of parallel software to be treated effectively, and as first-class citizens. This methodology was built into a toolbox for developing highly parallel software for low-energy systems, as required by the internet of things, cyber-physical systems etc.

The TeamPlay approach allows programs to reflect directly on their own time, energy consumption, security, etc., as well as enabling the developer to reason about both the functional and the non-functional properties of their software at the source code level.

...
\vspace{-8pt}
\paragraph{\rephrase (ICT-644235).}
%\vspace{-12pt}

The \rephrase project aims to study the software engineering process as
a whole for heterogeneous parallel machines
using C++.  It considers neglected, but important, issues such as
effective testing, debugging, maintenance and quality assurance for
multicore/manycore machines, and involves major industry players such as IBM.
\emph{\TheProject will, however, substantially extend the work that has been done in \rephrase by:
\begin{inparaenum}[i)]
\item XX
\end{inparaenum}}

\vspace{-2pt}
\paragraph{\paraphrase (ICT-288570).}
%\vspace{-12pt}
% \TOWRITE{CB,VJ}{Write about ParaPhrase} 
The \paraphrase project introduced a new structured design and implementation process for
heterogeneous multicore/manycore architectures, in which developers exploit a variety of
parallel patterns to develop component based applications in Erlang and C++. These
component based pattern-applications may then be re-mapped to meet the
application requirements and hardware availability. 
\vspace{-2pt}
\paragraph{\grow (EU No.690199).}
The \grow project (funded from the European Union’s Horizon 2020 research and innovation programme under grant agreement No.690199) is the first continental-scale Citizens’ Observatory to monitor a key parameter for science, continuously over an extended period, and at an unmatched spatial density. \grow has, for the first time, used crowdsourced ground observations from low-cost sensors to validate soil moisture information from satellites, including the new generation of high-resolution satellites, Sentinel-1.

24 \grow communities in 13 European countries create an unprecedented network of 6,502 ground-based soil sensors and a dataset of 516M rows of soil data. 

\paragraph{\weobserve (EU No.776740).}
\weobserve is an umbrella project promoting the use of Citizen Observatories for environmental monitoring.  This innovative project aims at demonstrating the societal and economic benefits of involving citizens in environmental decision making and cooperative planning, supporting Europe’s leading role in integrating citizen science and building resilient communities. Together, these projects will empower and enable citizens to become the ‘eyes’ of the policy makers and to complement existing environmental monitoring systems.

\subsubsection{Overall approach and methodology}

\eucommentary{Describe and explain the overall approach and methodology, distinguishing, as appropriate, activities indicated in the relevant section of the work programme, e.g. for research, demonstration, piloting, first market replication, etc.;}

\TheProject{} comprises 6 technical work packages: WP2 on secure patterns for distributed machine-learning based data analytics; WP3 on security and privacy of data storage and AI-based data analytics; WP4 on identifying security vulnerabilities and self-healing technology; WP5 on intelligent user authentication; WP6 on methodology for developing secure applications by end users; and WP7 on use cases and evaluation. The relationship between the project objectives and these workpackages is shown below

\vspace{-8pt}
\begin{center}
\begin{tabular}{|l|l|l|}\hline
\textbf{Objective} & \textbf{Purpose} & \textbf{Contributing WPs} \\\hline \hline
Objective 1 & Secure Patterns for Distributed AI-based Data Analytics & \textbf{WP2}, \textbf{WP3}, \textbf{WP4} \\\hline
Objective 2 & Identifying Vulnerabilities and Privacy Leakage & \textbf{WP3}, \textbf{WP4} \\\hline
Objective 3 & Self-Healing Techniques for Repairing Vulnerabilities and Leakage & \textbf{WP3}, \textbf{WP4} \\\hline
Objective 4 & Coding Standards for Developing Secure Distributed Applications & \textbf{WP2}, \textbf{WP6} \\\hline
Objective 5 & Intelligent User Authentication-as-a-Service & \textbf{WP5} \\\hline
Objective 6 & Refactoring-Based Methodology for Secure Applications & \textbf{WP3}, \textbf{WP4}, \textbf{WP5}, \textbf{WP6} \\\hline
Objective 7 & Demonstrating the Tools and Techniques on Real-World Use Cases & \textbf{WP7}\\\hline
Objective 8 & Building a Sustainable User Community & \textbf{WP8}\\\hline
\end{tabular}
\end{center}

\paragraph*{Work Programme for Objective 1.}

Objective 1 aims to build secure patterns for distributed AI-based data analytics and to develop methods for formal specification and verification of security properties of those patterns. In WP2, we will develop secure patterns for distributed AI-based data analytics, as well as the methods for formal specification and verification of security and privacy properties of pieces of C++ code, in form of \emph{security certificates} that will specify these properties at a high level and also \emph{security contracts} that will be machine readable and, therefore, amenable for formal proving. In WP4, we will develop tools that will identify security risks in the existing C++ code, which will then be used in WP2 in the process of developing secure patterns. In WP3, we will apply these techniques to identify security vulnerabilies in storage and processing of data in AI models, as well as to identify and control leakage of sensitive data in building and exploiting these models. 

\paragraph*{Work Programme for Objective 2.}

Objective 2 aims to develop techniques for identifying security vulnerabilities and data leakages in the C++ code. In WP4, we will develop fundamental techniques for identifying security vulnerabilities. These techniques will be based on static code analysis, as well as on dynamic symbolic execution of the code. In WP3, we will apply these techniques to identifying security vulnerabilities in distributed databases and machine-learning based distributed data analytics applications. WP3 will also investigate privacy leakage in machine-learning, both when building models on the training data and when the models are actually applied. The developed diagnostics for identifying vulnerabilities and leakages will be integrated into the overall \TheProject{} methodology in WP6.

\paragraph{Work Programme for Objective 3.}

Objective 3 aims to develop self-healing mechanisms for repairing security vulnerabilities and privacy leakage. In WP4, we will develop a foundational code transformations for self-healing. These transformations will be based on the identified vulnerabilities, as well as on the known secure code patterns for distributed data analytics, as developed in WP2. In WP3, we will develop techniques for applying these transformations both to the end-user code that uses distributed databases for data storage and that uses common pattern-based data analytics frameworks such as XX. WP3 will also develop techniques for controlling data leakage using optimal noise-adding mechanisms. In WP6, the transformations will be integrated into the software-refactoring based methodology for deveoping secure pattern-based distributed data analytics applications. 

\paragraph{Work Programme for Objective 4.}

Objective 4 aims to extend the existing code standards for developing secure and privacy-preserving distributed applications. In WP2 and WP6, we will build on the existing C++ security standards, such as XX, extending them with the new rules identified over the course of the project. We will also develop static analysis techniques for verification that the given C++ code conforms to these extended security standards. This analysis will be integrated into the overall \TheProject{} methodology in WP6.

\paragraph{Work Programme for Objective 5.}

Objective 5 aims to analyze, design, develop and evaluate an intelligent and user-centered authentication-as-a-service which will allow digital service providers to integrate, deploy and manage multi-factor authentication (MFA) and continuous user authentication by reducing the complexity of development. A User-Centered Design (UCD) methodology will be followed for the design and development of the authentication technology aiming to assure that the solution meets the users' needs and expectations in terms of usability and security. The development life-cycle of the authentication component will include multiple design iterations and a significant amount of evaluation, which will be largely based on studies with the active participation of real end-users. These studies will be both formative (during the project’s course, with the aim of validating/refining the initial design) and summative (towards the end of the project, aiming to measure the quality and effectiveness of the final project results). The UCD approach will embrace three iterative cycles leading to three different system prototype releases (low-fidelity, high-fidelity, final release). Each iteration entails an analysis, design, implementation and integration, ending with an evaluation of derived prototypes providing thus valuable feedback for designing the next release. 

\paragraph{Work Programme for Objective 6.}

\paragraph{Work Programme for Objective 7.} 

Objective 7 is to demonstrate effectiveness of the \TheProject{} approach on the real-world use cases from the air traffic control, telecommunications, banking and medical domains. In WP6, we will develop a tool-chain that will integrate all different techniques developed in WP2 -- WP5. This will be used in WP7 to evaluate the \TheProject{} technology  on use cases from XX, XX and XX. We will apply our techniques both on analysing/repairing the existing and on developing completely new distributed code from the chosen domains. While our ultimate goal is to test the techniques in realistic setting, \emph{data fabrication} methods that will be developed as a part of the methodology will allow us to produce immediately produce arbitrary amount of realistic data for rapid development and testing of our techniques. We will demonstrate increased security of the end-user software while at the same time decreasing cost of the production, deployment and maintenance of such a system.

\paragraph{Work Programme for Objective 8.}

Objective 8 is to ensure long-term uptake and use of \TheProject{} concepts and technologies. In WP8, we will undertake a range of dissemination and communication activities, that will include producing publications, documents and other materials, giving presentations and demonstrations, running dedicated workshops and tutorials to encourage uptake of \TheProject{} technologies, establishing and maintaining a communication strategy, producing of user-level documentation and training material, including tutorials, webinars etc., production and distribution of promotional and informational materials, including press releases, flyers etc., and updating and managing the web portal with user-related material. Uptake and use will be assisted by the inclusion of the highly-relevant use cases from the air traffic control, telecommunications, banking and medical domains.


\subsection{Ambition}

\eucommentary{Describe the advance your proposal would provide beyond the state-of-the-art, and the extent the proposed work is ambitious. Your answer could refer to the ground-breaking nature of the objectives, concepts involved, issues and problems to be addressed, and approaches and methods to be used.}

\subsubsection{Advances Beyond the State-of-the-Art}
\label{sec:novelty}
\label{sect:background}
\label{sect:state-of-the-art}

%\eucommentary{}


\TOWRITE{ALL}{Add sections on your own technologies/update
what's here.}

The \TheProject{} project will revolutionise XX by:
\begin{itemize}
\item XX
\end{itemize}

\subsubsection{Distributed Machine-Learning Based Data Analytics}
\label{sect:background-first}
\label{sect:distAnalytics}
\vjcomment{UOD and SCCH to write}

\subsubsection{Formal Specification and Proving of Security Properties}
\label{sect:formal}
\vjcomment{USTAN to write}

\subsubsection{Parallel Patterns for Distributed Data Analytics}
\label{sect:patterns}
\vjcomment{UOD to write}

\subsubsection{Coding Standards for Security}
\label{sect:codingStandards}
\vjcomment{UC3M to write}

\subsubsection{Identifying Security Vulnerabilities}
\label{sect:security}
\vjcomment{IBM and DEMOCRITOS to write}

Application security is becoming increasingly important in modern computer systems.
Current practice is for security to be ensured at runtime, using efficient monitoring
techniques coupled with dynamic runtime checks such as ISR~\cite{isr}, ASLR~\cite{aslr}
and CFI~\cite{cfi}. These methods are, however, expensive in terms of computational
complexity and energy consumption. As most of the security vulnerabilities come from
code defects, bugs and logic flaws, the most cost-effective way to ensure security is
to follow the secure code best practices~\cite{OWASP} and eliminate vulnerabilities
before code is deployed. This is usually done with static and dynamic code analysers.
Static code checkers, such as Appscan Source~\cite{AppScan} and Coverity~\cite{Coverity}
%and Klocwork~\cite{Klocwork}, 
are based on techniques for quality checking that
have been extended to cover security vulnerabilities in the code. The main drawback of 
these methods is their high rate of false positives they produce. Techniques based on
formal methods, such as model checking and symbolic interpretation, do not report false 
positives, but have potential problem with scaling. AFL~\cite{AFL} uses use fuzz testing 
to dynamically profile the code to expose potential security vulnerabilities. 
None of the above tools includes special algorithms for detecting vulnerabilities 
resulting from parallel execution. Parallelism, due to undeterministic nature of the
application execution, presents many additional problems from the security perspective. These problems have to be dealt with efficiently
in future systems.


Including third party libraries into the application code presents additional
security risks, as these libraries may include intentional or unintentional
vulnerabilities resulting in unwanted behavior or data leakage of sensitive 
information. For example, an open source JavaScript library used in a website 
may contain malicious code that collects data and sends it to the third party. 
%Another example is binary packages which contain vulnerability which is detected by crackers and compromise users??? machines. 
The state of the art solutions to this problem is to use security testing, static 
analysis and dynamic analysis, such as sandboxing~\cite{jsand}, to detect 
vulnerabilities and malicious packages before integrating them into 
the application code. % is proposed to detect malicious JavaScript code, in addition, they 
%suggest wrapping the components to control access to security sensitive operations. 
In~\cite{Cova}, a combination of anomaly detection and emulation systems is built to detect malicious code. OWASP~\cite{OWASP} presents the risks in using third party 
packages, how to determine if these packages are vulnerable or contain malicious code 
and how to deploy these packages. %This problem is not met only in JavaScript packages, it is in many other 3rd party packages, especially, Android 3rd party libraries. 
Other possible solutions to the problem of integrating third party libraries are
based on analysis of the libraries, building control flow graph, looking for 
copies of buggy code, and profiling packages~\cite{Hanna, XinSun}.%~\cite{Hanna, XinSun, Nora, Backes}.
These solutions miss many vulnerabilities or malicious dormant code as a result of 
obfuscation, packing, and the ease in rebuilding new variants of the malicious code, 
or just the rapid release of new buggy version of packages.

There are cases in which it is not beneficial to fix a vulnerability in the 
software or in a third party code integrated into the software. For example, 
in cases where the patch is hard to deploy or where fixing the vulnerability 
has significant impact on performance. In fact, 99\% of attacks are believed to exploit known and fixed vulnerability~\cite{GartnerVulnerability} for which the fix was not deployed. One famous example is the WannaCry attack that was based on a fixed and updated CVE.
To protect the software in these cases,
\emph{virtual patching} may be used. %Virtual patching is a security policy 
%enforcement layer which prevents the exploitation of a known vulnerability. 
A virtual patch is a set of rules that implements complex logic to prevent 
malicious traffic from reaching the application. 
%The virtual patching mechanism will usually be integrated in the organization firewall. 
The challenge is to come up with a set of accurate rules that filter 
exactly the malicious inputs without blocking other inputs. This work is 
currently done manually, and it would heavily benefit from integrating a 
predictive model to automatically detect inputs that may utilize the 
vulnerability.




\TheProject{} will advance the state-of-the-art of security of parallel code in the following directions:
\begin{itemize}
\item XX
\end{itemize}

\subsubsection{Authentication}
\label{sect:auth}
\vjcomment{COGNITIVE to write}

Researchers and practitioners have attempted to provide various \textit{solutions for multi-factor authentication (MFA)} such as tokens based on push notifications on smartphones, Time-based One Time Passwords (TOTP), Quick Response (QR) codes, graphical Transaction Authentication Numbers (PhotoTANs) [REF]. With regards to \textit{continuous user authentication}, several works proposed solutions based on users’ interaction behavior analysis on both desktop computers and smartphones [REF], physiological data analysis such as body signals (heart rate, skin conductance, etc.) [REF] and face biometrics [10, 11], and eye gaze data analytics [REF]. Various organizations and companies also exist that are either adopting MFA, or continuous user authentication (e.g., Cisco’s Duo Security (https://duo.com), Futurae (https://futurae.com), Acceptto (https://acceptto.com), Auth0 (https://auth0.com), Saaspass (https://saaspass.com)), however, these are far from fully adopting solutions that combine MFA and continuous user authentication. 

\subsubsection{Security Patterns}
\vjcomment{USTAN and UOD to write -- possibly merge with the previous subsections?}
\begin{itemize}
	\item Design pattern
	\item parallel patterns or skeletons
	\item abstractions over low-level implementation
	\item provided as a library
	\item structured approach
	\item extended for security
	\item new patterns X Y Z
\end{itemize}

\subsubsection{Refactoring}
\vjcomment{USTAN to write}
\begin{itemize}
	\item Refactoring history
	\item program transformation
	\item refactoring used as a software engineering strategy
	\item structural changes to the code
	\item refactoring to introduce parallel patterns
	\item will be extended to introduce security patterns, fix vulnerabilities, adhere to standard
	\item some aspects may be proved correct
\end{itemize}

In essence, refactoring is about changing the structure of a program's source code in such a way that the change does not alter the functional behaviour of the program. It is a software engineering practice that is used daily by developers, who restructure code to make it more amenable to maintenance and extension. Refactoring is also a technique that is usually practised \emph{manually} by developers. The downside of manual refactoring is that it becomes very error-prone over large code bases; it also requires the refactorer to be an expert in the particular structural change that is being implemented. Refactoring tools, on the other hand, automate the process, allowing machine-checkable pre- and post-conditions to automatically ensure that the refactored code is functionally correct to the original. 

Automated refactoring has roots in a long history, with the original refactoring work going back to the \emph{fold/unfold} system proposed by Bustall and Darlington in 1977~\cite{cfs}{darlington77}. Since then, refactoring has been applied to a wide range of applications as an approach to program transformation~\cite{cfs}{Mens:2004:SSR:972215.972286}, with refactoring tools a feature of popular IDEs including, \textit{e.g.}, Eclipse and Visual Studio.

\subsubsection{Use Cases}
\label{sect:applications}
\label{sect:background-last}
\vjcomment{FREQUENTIS, DEMOCRITOS and SOPRA to write}

\paragraph{Aviation}
\label{sec:swim}
- Various stakeholders in aviation are facing two key challenges: the requirement to migrate from ATS Message Handling System (AMHS) to System Wide Information Management (SWIM), and the requirement to integrate Unmanned Traffic Management (UTM) with ATM. SWIM is an integral component of the digital transformation that is taking place in the Aviation industry. This digital transformation is having a major impact, as not only systems but also new processes and new staff expertise are required Today Air Navigation Services Providers (ANSPs) rely on closed systems with proprietary point-to-point communication for data exchange. SWIM will enable these systems to operate as an overlay to IP networks using open standards and Air Traffic Management (ATM)-defined data exchange models (Aeronautical Information Exchange Model (AIXM), ICAO Meteorological Information Exchange Model (IWXXM), Flight Information Exchange Model (FIXM). 
Such a platform shall act as an information backbone for connecting all aviation stakeholders supporting all aviation exchange models and legacy protocols and data formats to facilitate transition to SWIM. It shall be specifically designed to assist the Aviation industry with its migration to SWIM and to facilitate the exchange of information between all industry stakeholders for better informed decision making and the creation of new applications and services.

\paragraph{Open banking}
\label{sec:banking}
- As the digital disruption moves the banking services closer to the end-user more diverse software tools are deployed into the banking workflow via open banking solution. We plan to look at how we auto-generate data processing code for a processing hub for Competition and Markets Authority (CMA)nine largest banks in the United-Kingdom. We will use the tools we develop during the research to secure the auto-generated code.

\paragraph{Space-based Open Internet}
\label{sec:spacenet}
- As the digtal access in the world moves to a more cost effective hybrid space and ground solution the use of Delay/Disruption Tolerant Networking (DTN) and Solar System Internet (SSI) technology opens the global communication system to penetrate into more remote areas and will but more social care and healthcare systems onto the open internet. We want to ensure we create code to deploy into these edge computing devices that can auto-heal their security vulnerabilities.

\paragraph{Distributed healthcare (IoT)}
\label{sec:health:IoT}
- As more sensors enter into the Distributed healthcare (IoT) domain the code for these sensors, edge collection devices and core processing capability will start becoming a life-threatening issue if any vulnerability causes the unwanted outcome of a patients health. We want to ensure we can auto-heal our solution to auto-heal our citizens.

\paragraph{Sovereign Identity Clearance House}
\label{sec:ssi}
- As the Self-sovereign identity (SSI) tokens are developed the highly-distributed tokens has to be updated and secured before they are accepted as "true" Sovereign Identity tokens. The issue is to validate the tokens integrity not the identity content. We want to research how do you support a token within a highly secure ecosystem without any vulnerabilities.

\subsubsection{Key Technologies Used in the \TheProject{} Project}
\label{sect:key-technologies}

\paragraph{\SCCHshort{} Machine Learning Tools.}
\label{sec:mlpp}
\emph{mlpp} is a C++ library with interfaces to several other languages. It 
is currently under heavy development. So far, it contains algorithms for 
linear regression, time series analysis, feature selection and causal 
dependency discovery. Its focus is on building interpretable models. It is hosted 
on SourceForge (\url{https://sourceforge.net/projects/ml-pp/}), and released 
as Open Source (GPL license); paid licenses for commercial use will be provided
with the first mature release.

\paragraph{\IBM{} Security Vulnerability Detection Technology.}

IBM developed vulnerability detection technologies based both on static and dynamic methods. IBM developed Beam for static analysis of C/C++ code and extended it to look in particular for security vulnerabilities with a low ratio of false positive. In addition, IBM developed the ExpliSAT tool which uses symbolic interpretation for more precise program analysis including checks for security vulnerabilities such as buffer overflow detection. During the \rephrase{} project, ExpliSAT was extended to analyse parallel programs. To complement the static methods IBM uses also Fuzz testing technology that detects security vulnerabilities dynamically using genetic algorithms. In order to achieve accurate and scalable security vulnerability detection, IBM is now working on combining the static and dynamic analysis vulnerability detection tools.     

\paragraph{\SAshort{} \paraformance Refactoring and Code Analysis Tools.}


The \paraformance Refactoring tool was originally developed for the EU FP7 \paraphrase{} project, and later extended and enhanced in both \rephrase{} and the Scottish Enterprise innovation project, \paraformance{}. 
\paraformance is a tool-chain designed to \emph{democratise} parallel programming by allowing software developers to quickly and easily write parallel software. \paraformance enables software developers to find the sources of parallelism within their code, automatically (through user-controlled guidance) through a process of \emph{pattern discovery}. \paraformance also offers refactoring support to allow parallel patterns to be introduced directly into the source code of the application, inserting the parallel business logic. \paraformance also has integrated safety checking features, to not only enable  the parallelised code to be thread-safe, but also the checking of sequential code, eliminating potential sources of parallelism errors that occur, such as race conditions and deadlocks. Finally, \paraformance is able to repair some of the parallelism errors detected by the safety checking to automatically make the application thread safe. \paraformance will be extended in \TheProject{} by adding safety checks for the distributed code, in addition to the existing mechanisms for checking the code that is executed on shared-memory machines. We will also extend the tool with features to check for \emph{security} of the code. 

\paragraph {\SAshort{} CSL: The Contract Specification Language}
CSL (Contract Specification Language) was developed as part of the ongoing H2020 \teamplay{} project. It is designed to act both as an annotation library for C applications, allowing the developer to annotate their source code both to reflect non-functional properties of time, energy and security back into the source code, but also in order to express assertions ---or contracts--- about the non-functional properties. Such non-functional properties could be, for example, the worst-case execution time (or energy) of a block of code, the security vulnerability level of a variable, etc. The assertions themselves are expressed in terms of these properties and other normal variables within the source code. The properties can also be reflected back into the source-program as first-class citizens: normal programming variables with values in the source-level space.
The assertions are then passed to an underlying proof system together with an abstract interpretation of the C program. This proof system (currently implemented using the dependently typed language, Idris) produces  a proof of whether or not the assertion can be met. CSL will be extended in \TheProject{} by adding ... 

\paragraph{\FRQshort{} MosaiX SWIM: Aviation Integration Platform}
\label{sec:swim}
The Frequentis Integration Platform is an end-to-end solution that provides aviation stakeholders (ANSPs, airports, airlines, met offices) with tools required to unlock and monetize their data by offering new services to their customers (i.e. airlines). It allows aviation stakeholders to easily interface with legacy and third-party systems, enabling data to be freed from traditional storage silos and fused with different sources. MosaiX SWIM is designed around a microservices architecture and an open messaging system in which all software components exist as independent artefacts and communicate in a decoupled way. This reduces vendor lock-in by allowing customers to substitute components and incorporate new technologies in the future. The platform provides an efficient API Manager and tools for billing consumers of services using models such as hourly billing or consumption-based billing. In addition, it offers preconfigured and customisable metrics and dashboards, together with data-analysis tools.



\subsubsection{Innovation Potential}
\label{sec:innovationpotential}
\label{innovationpotential}

\eucommentary{Describe the innovation potential which the proposal represents. Where relevant, refer to products and services already available on the market. Please refer to the results of any patent search carried out.}

\clearpage
\section{Impact}
\label{sec:impact}

\TODO{Look at this once the rest of the project is together.}

\eucommentary{Describe how your project will contribute to:\\
o the expected impacts set out in the work programme, under the relevant topic;\\
o improving innovation capacity and the integration of new knowledge (strengthening the competitiveness and growth of companies by developing innovations meeting the needs of European and global markets; and, where relevant, by delivering such innovations to the markets;\\
o any other environmental and socially important impacts (if not already covered above).}


\subsection{Expected Impacts}

%\eucommentary{

{\color{blue}{
  Expected Impact:
In the short term, project outcomes should make relevant contributions to the following:
\begin{itemize}
\item reduced number and impact of cybersecurity incidents;
\item efficient and low-cost implementation of the NIS Directive and General Data Protection Regulation;
\item effective and timely co-operation and information sharing between and within organisations as well as self-recovery;
\item availability of comprehensive, resource-efficient, and flexible security analytics and threat intelligence, keeping pace with new vulnerabilities and threats;
\item availability of advanced tools and services to the CERTs/CSIRTs and networks of CERTs/CSIRTs;
\item an EU industry better prepared for the threats to IoT, ICS (Industrial Control Systems), AI and other systems;
\item self–recovering, interoperable, scalable, dynamic privacy-respecting identity management schemes.
\end{itemize}

  In the medium to long term, project outcomes should make relevant contributions to the following:
\begin{itemize}
\item availability of better standardisation and automated assessment frameworks for secure networks and systems, allowing better-informed investment decisions related to security and privacy;
\item availability and widespread adoption of distributed, enhanced trust management schemes including people and smart objects;
\item availability of user-friendly and trustworthy on-line products, services and business;
\item better preparedness against attacks on AI-based products and systems;
\item a stronger, more innovative and more competitive EU cybersecurity industry, thus reducing dependence on technology imports;
\item a more competitive offering of secure products and services by
  European providers in the Digital Single Market.
\end{itemize}
}}

%}


The table below summarises how the \TheProject{} project will achieve impact in the areas expected by the Work Programme.


\begin{longtable}{|p{125pt}|p{320pt}|}%\hline

\hline \textbf{Expected impact}&

\textbf{How will \TheProject{} achieve this impact?}\\\\ \hline
\endfirsthead

\multicolumn{2}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous
page}} \\ \hline \textbf{Expected impact}&

\textbf{How will \TheProject{} achieve this impact?}\\\\ \hline
\endhead

\hline \multicolumn{2}{|r|}{{Continued on next page}} \\ \hline
\endfoot

\hline \hline
\endlastfoot

\vspace{10pt}
\\
 \hline
\end{longtable}

%\draftpage
% \subsubsection*{Improving Innovation Capacity}
%\draftpage

\pagebreak
\paragraph*{Improving Innovation Capacity}
\noindent

\paragraph*{Societal Impact.}
\noindent
\subsubsection*{Possible Barriers to Achieving the Expected Impacts and Associated Mitigations}

\newcounter{barrier}

\begin{longtable}{|p{125pt}|p{320pt}|}%\hline

\hline \textbf{Possible Barrier}&

\textbf{Mitigation}\\ \hline
\endfirsthead

\multicolumn{2}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous
page}} \\ \hline
 \textbf{Possible Barrier}&

\textbf{Mitigation}\\ \hline
\endhead

\hline \multicolumn{2}{|r|}{{Continued on next page}} \\ \hline
\endfoot

\hline \hline
\endlastfoot


\addtocounter{barrier}{1}
\noindent
\emph{Barrier \thebarrier.}
\par \emph{Barrier 1:}

&
\noindent
XX
\end{longtable}

%\draftpage
\subsection{Measures to Maximise Impact}

The impact of \TheProject{} will be maximised by:
\begin{inparaenum}[i)]
\item
  XX
\end{inparaenum}
%
The following section describes these measures in more detail.

\subsection{Dissemination and Exploitation of Results}
\label{sect:dissemination}

\eucommentary{Provide a draft 'plan for the dissemination and exploitation of the project's results' (unless the work programme topic explicitly states that such a plan is not required). For innovation actions describe a credible path to deliver the innovations to the market. The plan, which should be proportionate to the scale of the project, should contain measures to be implemented both during and after the project.
Dissemination and exploitation measures should address the full range of potential users and uses including research, commercial, investment, social, environmental, policy making, setting standards, skills and educational training.
The approach to innovation should be as comprehensive as possible, and must be tailored to the specific technical, market and organisational issues to be addressed\\
o Explain how the proposed measures will help to achieve the expected impact of the project. Include a business plan where relevant.\\
o Where relevant, include information on how the participants will manage the research data generated and/or collected during the project, in particular addressing the following issues:\\
o What types of data will the project generate/collect? o What standards will be used? o How will this data be exploited and/or shared/made accessible for verification and re-use? If data cannot be made available, explain why.
o How will this data be curated and preserved?}



\subsubsection{Draft Dissemination Plan}

We will focus on propagating our results both to the computer science
research community and to potential users of the \TheProject{} technology.
We will do this through a mixture of high-quality publication, presentations
and direct engagement with the user community.
%
The main research communities that we expect to target are:
XX
% 
We anticipate that the primary users of our technology will be:
XX.

\paragraph{Scientific Publications:}  The main routes to good scientific dissemination are
through peer-reviewed publication, and through presentation of results at key scientific events.
\TheProject{} partners will therefore aim to produce high-quality \emph{peer-reviewed
research publications} in relevant leading
conferences, technical workshops and journals.
We will build on the existing good publication records of the \TheProject{} partners,
aiming to produce a sizeable volume of good quality publications in the course of the project. 
%
\noindent
The conferences that we propose to target include:
\vjcomment{Update these.}

\begin{quote}
\textbf{ICSE:} International Conference on Software Engineering;
 \end{quote}

\noindent
We also propose to target relevant high-impact journals such as:
\begin{quote}
\emph{the ACM Transactions on Software Engineering and Methodology (TOSEM)}, 
\end{quote}

\paragraph{Project Web site:}  
A crucial component of the \TheProject{} dissemination strategy is a
high-quality project website. The public section will provide ample
and consistent information about all aspects of the \TheProject{}
project, with the goal of positioning the \TheProject{} website as a
prime information source for relevant scientific and technical
information.  The vast majority of the \TheProject{} deliverables are
public, and full access to these will be provided.  The web site will also contain lists of publications and links
to open-access repositories; copies of technical reports and white
papers; a news feed; technical documentation; downloadable software
and pre-installed virtual machines; video demonstrations; online
tutorials; information about project partners; copies of
presentations, podcasts and other material; data and results; plus
links to the Horizon 2020 programme in general and to related 
Horizon 2020 research projects in order to highlight the role played by \TheProject{} within the
broader EC research framework.

\paragraph{Project News Feed:}  We will set up open public mailing lists/twitter/facebook accounts that will
be used to communicate project news and results to interested parties, whether they are scientists, academics, developers
or the general public.  This news feed will be highlighted on the project web site.

\paragraph{Developer and User Community:} We will engage with the broader
developer and user communities by a series of focused activities
that will include the organisation of dedicated user community workshops, presentations at
 developer and other conferences, 
 the production of posters, delivering tutorials, staffing booths, and providing hands-on
 guidance in the use of our tools and technologies etc.  This direct engagement will be
 supported by the production of video demonstrations, training materials, tutorials and documentation that can
 be accessed through the project web site.  We will also aim to produce white papers and slide sets that
 can be used to explain the benefits of the \TheProject{} approach to prospective users, both developers
 and managers.

 \paragraph{Expert Working Groups and Networks of Excellence:}
In order to ensure good dissemination to the research and development
community, including industrial researchers, we propose to disseminate
our project results through the most relevant scientific/technological
networks and working groups, including HiPeac,%  the TACLe Cost Action on Timing Analysis, the Ercim DES Working Group, 
IFIP Working Groups 2.11 \& 10.3, and other EU and national projects,
as well as national groups such as the UK's network on manycore computing.
\SAshort{} is a full member of HiPeac and a charter member of IFIP working
group 2.11, and has been heavily involved in activities organised by these and other expert groups.
These provide a high-level interface between academic and industrial interests, and a valuable
melting pot for ideas and new technologies. 

\paragraph{Standardisation Committees:}
% \khcomment{We should mention any committees that we are members of. Remove this section if not relevant.}
This proposal is tied to Standards from the beginning, through the end and beyond. It leverages the key leadership position of several members, acting as senior leaders, officers, working group experts, proposal authors, collaboration with other industry and academic experts.
%% Doesn't make sense?
% Current C++ Standards only support CPU, though it is adding parallel programming support starting with C++ 11, enhanced through C++ 17 with parallelSTL. Yet it is still lacking many things that can support Heterogeneous computing, which has been already explored by SYCL and OpenCL. 
%
%

\paragraph{General Scientific and Technical Community:}
We will further engage with the general scientific and technical community
 by participating in relevant workshops, conferences and clustering events (including ones which
 will develop our technologies beyond the bounds of our own research communities), by engaging with the
 different EC-sponsored CORDIS information channels, by presenting at trade
 fairs, and through other dissemination activities.  We will use materials such as presentations,
 papers,  posters, demonstrations and the project web site to do this.


\paragraph{Education:} We will target 
the educational communities through the production of relevant educational materials, that will
also have a training benefit. Young researchers, software
 developers and application programmers will learn how to
 use our software technologies in their
 respective fields. This is aligned with recent EC
 initiatives on the subject such as ``Increasing the Attractiveness
 of Science, Engineering \& Technology Careers''.
 The academic consortium partners will integrate Bachelor,
 Master, Diploma, and PhD students into the \TheProject{}
 project whenever possible, e.g.~through PhD and MSc theses, student
 projects, academic courses, and research seminars. 
 We will also take advantage of opportunities to engage with broader
 audiences through guest lectures at other institutions and summer schools etc.
 These students will
 carry the methodology and techniques of the \TheProject{}
 project into their future work places in the ICT industry.
 In that way the \TheProject{} vision and the project
 results will disseminate into many research groups and
 companies working in the field of security. 
 \paragraph{MOOC:}In order to disseminate security and the work of the consortium to the wider public a MOOC (massively open online course) will be developed to reach an audience far beyond the academic and industrial community.  MOOCs provide access, often to hundreds or thousands of people at a time, to focused online courses with learning goals and paths that present the opportunity to learn together at a flexible pace. Participants start and complete the training course on the MOOC at the same time as a cohort, to create community and for peer learning. The provision of a MOOC will also be
used to enthuse and educate citizens about security and in particular the work of the project.  Work packages will provide accessible materials (text, videos, audio clips) highlighting the work that is being carried out. UoD brings a long‐term, established partnership to a market leading MOOC, FutureLearn, which will be supported far beyond the funded period. The FutureLearn MOOC is free and open, and brings a highly scalable platform into the project ecosystem, capable of sustaining more than 100,000 learners at one time.

% \paragraph{General Communication:} We will adopt a good general communication strategy
% aimed at maximising the outreach of the \TheProject{} project to the public at large.  We will issue
% regular press releases describing relevant events and research results, conduct
% radio/TV interviews, adopt an open policy to disseminating our research results through use of appropriate
% repositories for publications and the project web site, use public media such as
% \emph{twitter} to communicate project results, engage with public lectures and seminars,
% write general articles for newsletters, newspapers etc. as described in \ref{wp:dissem}.

\begin{quote}

\emph{Although all these dissemination activities
will be centrally coordinated, the full and active participation of
all partners is expected. Key project representatives from
the various \TheProject{} academic and industrial
partners will also arrange specific meetings
with scientific, commercial, industrial, and/or
governmental representatives to facilitate public
engagement.}
\end{quote}

\subsubsection{Draft Exploitation Plan}
\label{sect:exploitation-plan}
\vspace{-12pt}

All partners will have the right to use foreground IPR for
the purposes of the project. In order to ensure that all
contributions are recognised, exploitation plans will be
shared with the consortium as a whole. Partners will not,
however, have the right to veto or delay exploitation
unless their own IPR is directly involved.


\horizontalline

\subsection*{Draft Exploitation Plan for \IBMshort{}}


\begin{wrapfigure}{R}{4cm}
\vspace{-1.4cm}
\hfill \includeimage[width=4cm]{logos/ibm.jpg}
\vspace{-0.6cm}
\end{wrapfigure}

\horizontalline

\subsection*{Draft Exploitation Plan for \SCCHshort{}}
\vspace{-6pt}

\begin{wrapfigure}{R}{3.6cm}
\vspace{-1.3cm}
\hfill \includeimage[width=4cm]{logos/SCCH.jpg}
\vspace{-0.8cm}
\end{wrapfigure}

\horizontalline

\subsection*{Draft Exploitation Plan for \SAshort{}}

\begin{wrapfigure}{R}{2cm}
\vspace{-1.4cm}
\hfill \includeimage{logos/st-andrews-logo.jpg}
\vspace{-0.9cm}
\end{wrapfigure}

\subsubsection{Knowledge Management and Protection}
\vspace{-12pt}

\eucommentary{Outline the strategy for knowledge management and protection. Include measures to provide open access (free on-line access, such as the 'green' or 'gold' model) to peer-reviewed scientific publications which might result from the project}

Before the project starts, all project partners will agree on explicit rules concerning IP ownership, access rights to any
Background and Results for the execution of the project and the
protection of intellectual property rights (IPRs) and confidential
information as part of the Consortium Agreement.
As part of the Consortium Agreement, in order to ensure a smooth
execution of the project, the project partners will agree to grant each other
royalty-free Access Rights to their Background and Results for the
execution of the project. The Consortium Agreement will define further
details concerning the Access Rights after the duration of the project 
with respect to Background and Results.

\paragraph{Dissemination and Communication:}
While fully taking into account issues of potential exploitation and IPR ownership by project partners
as governed by the Consortium Agreement,
the project aims to provide good general access to its research results.
Balancing access with cost, the project will therefore generally adopt a ``green'' model to open access for publications,
but has included funding to support targeted ``gold'' open access for key publications.
The academic partners all maintain suitable institutional repositories, which will allow public access to research papers produced in the
course of the project, perhaps with some moratorium.  Some publishers (e.g. the ACM) also provide links that allow
free access to their publications from authors' home pages, and this will be exploited wherever possible.
% y, where publisher charges are not excessive, the project will consider ``gold'' open access to key project publications.
%
Furthermore, and perhaps of most significance, the project website will provide free,
open and publicly searchable access to all the public deliverables, to technical reports, data and results, to software tools
and libraries, to white papers and also to all
the other non-confidential documents that are generated in the course of the project.  
% The material released in this way will represent the vast bulk of the scientific
% and technical output of the project.

%\subsubsection*{Intellectual Property Rights}

\pagebreak
\paragraph{IP Ownership.}

Results shall be owned by the project partner carrying out the work
leading to such Results. If any Results are created jointly by at least
two project partners and it is not possible to distinguish between the
contributions of each of the project partners, such Results, including
inventions and all related patent applications and patents, will be
jointly owned by the contributing project partners. In order to further
the competitiveness of the EU market, and to enhance exploitation of the
Consortium Results, each contributing party shall have full own freedom
of action to exploit the joint IP as it wishes, and further the goals of
the consortium. To promote this effort the contributing party will have
full own consideration regarding their use of such joint Results and will
be able to exploit the joint IP without the need to account in any way to
the other joint contributor(s).Further details concerning jointly owned
Results, joint inventions and joint patent applications will be addressed
in the Consortium Agreement.

\paragraph{Transfer of Results.}

As Results are owned by the project partner carrying out the work leading
to such Results, each project partner shall have the right to transfer
Results to their affiliated companies/organisations without prior notification to the
other project partners, while always protecting and assuring the Access
Rights of the other project partners.  Such use of Results will encourage
competitiveness of the EU market by creating broader uses of the Results
and opening up the markets for the Consortium's Results in all markets.

\paragraph{Open Source and Standards.}

A central aim of this consortium is to provide benefit to the European community.  Some of the project partners may be either using Open Source code in their deliverables or contributing their deliverables to the Open
Source communities. Alternatively, some of the partners may be contributing to Standards, be they open standards or other. Details concerning open source code use and standard contributions will be
addressed in the Consortium Agreement.

The base technologies being developed by the academic partners within the duration of the project will be published under Open Source Licenses except where specified under Intellectual Property Management to allow the broader community to benefit from the outcome of this project.

The major validated project results  will be contributed to the key international standardisation bodies  such as ISO, ITU and others where the consortium members take part in. 


\paragraph{Data Management Plan}
The primary research data that will be produced by the project will be the performance results that are reported in
various research publications.  This data will predominantly be scientific,
without confidentiality restrictions, and it will
therefore be made available through the project website, in line with the agreements that will be
made in the Consortium Agreement.  As far as possible, 
this data will be recorded in a human-readable form, such as plain ASCII text
or XML.  Where this is not possible, converters will be provided to make the data accessible to other researchers
in a human-readable form. 
The research data on the project website will be associated with the relevant research publications. 
We have budgeted for adequate disk and processing capacity to allow for the expected access to this data.
The project website will be maintained after the end of the project, but to ensure long-term continuity
and value, data will also be transferred to the \SAshort{} institutional data repository.

\draftpage
\subsubsection{Communication Activities}
\label{sect:comm-activities}

\eucommentary{Describe the proposed communication measures for promoting the project and its findings during the period of the grant. Measures should be proportionate to the scale of the project, with clear objectives. They should be tailored to the needs of various audiences, including groups beyond the project's own community. Where relevant, include measures for public/societal engagement on issues related to the project.}

As described in the draft dissemination plan above, and in the description of~\ref{wp:dissem} (page~\pageref{wp:dissem}),
the \TheProject{} project aims to communicate itself and its findings intensively to various communities.
Research publications and presentations will aim to target various groups of academic and industrial researcher,
including parallel programmers, big data researchers, and programming language
designers, and will add scientific weight and credibility to our findings.  Press releases and news articles will be used to communicate project results and major
project life events (start, finish, key milestones) to both a technical and general audience.
We will also take advantage of opportunities as they arise for radio/TV interviews, public seminars and general articles
in both the technical and non-technical press.
The project website will be used to provide open access to project results, public deliverables,
software tools, technical reports, white papers, (video) tutorials, podcasts etc., and will serve
as a key resource for those wishing to use the project results, whether they are acting as an academic researcher, scientific, commercial or independent
software developer, public sector worker,  educator or private individual.
By making research results public in this way, we especially aim to engage with the software developer
community, who may not normally have access to academic papers and reports.
We will disseminate information about our tools and standards directly to customers, aiming to
increase engagement with an already motivated group of developers/users.
We will run open technical workshops that will showcase our work to interested parties.
These will generally be co-located with major networking events, such as the annual HiPeac
conference and the HiPeac spring/autumn gatherings.
We will also engage with relevant industrial/developer conferences, grass-roots meetings, workshops etc.,
producing poster and demonstrations as necessary to communicate with the broader developer community
and especially with project managers and decision makers.
Finally, we will actively participate in standardisation activities through e.g. the ISO C++ standard committee and ITU FG-DPM to support IoT and Smart Cities and Communities,
aiming to influence development and awareness of the \TheProject{} results.

\clearpage

% ---------------------------------------------------------------------------
%  Section 3: Implementation
% ---------------------------------------------------------------------------


\clearpage
\section{Implementation}

\subsection{Work Plan --- Work Packages, Deliverables and Milestones}
\label{sect:workplan}


\begin{figure}[tp]
\begin{center}
\vspace{-5mm}
\begin{tabular}{ll}
%\hspace{-0.75in}
%\includeimage[scale=0.5]{RePhorm2Pert.pdf}
%\vspace{-25mm}
\end{tabular}
\caption{Overview of the \TheProject{} Workpackage Structure and Dependencies (PERT chart)}
\label{fig:wps}
\end{center}
\end{figure}

\subsubsection*{Overall Structure of the Work Plan}

The work plan is broken down into XX technical workpackages as shown
in \textbf{Figure~\ref{fig:wps}}: WP2 deals with XX.

\input{deliverables}

\bigskip\bigskip
\addtocounter{subsubsection}{1}
\addcontentsline{toc}{subsubsection}{\protect\numberline{\thesubsubsection}Work
Package List}
\fbox{\begin{minipage}{\textwidth}\begin{center}{\Large\bf
        Work package list} % (full duration of project)}
  \end{center}
  \end{minipage}}

\bigskip\bigskip

\begin{tabular}{|p{1.2cm}|p{9cm}|p{0.8cm}|p{1.35cm}|p{1cm}|p{0.9cm}|p{0.9cm}|}
\hline
{\bf Work \mbox{package} No} & {\bf Work package title} &
{\bf Lead \mbox{partic.} no.} &
{\bf Lead short name} &
{\bf Person months} & {\bf Start month} & {\bf End month} \\\hline 

\newcounter{wp}

\addtocounter{wp}{1}
\workpackageentry{\thewp}{USTAN}{24}{1}{36}
\addtocounter{wp}{1}
\workpackageentry{\thewp}{IBM}{XX}{XX}{XX}
\addtocounter{wp}{1}
\workpackageentry{\thewp}{SCCH}{XX}{XX}{XX}
\addtocounter{wp}{1}
\workpackageentry{\thewp}{USTAN}{XX}{XX}{XX}
\addtocounter{wp}{1}
\workpackageentry{\thewp}{COGNI}{XX}{XX}{XX}
\addtocounter{wp}{1}
\workpackageentry{\thewp}{UCM}{XX}{XX}{XX}
\addtocounter{wp}{1}
\workpackageentry{\thewp}{SOPRA}{XX}{XX}{XX}
\addtocounter{wp}{1}
\workpackageentry{\thewp}{UOD}{XX}{XX}{XX}

{\textbf{Total}} & & & &
\textbf{\large XX}&
&
\\\hline
\end{tabular}

\landscape

\subsubsection*{Work Plan Timing: GANTT Chart showing Task Dependencies and Information Flows}


%\vspace{-0.7in}
%\centerline{\hbox to \columnwidth{\hss%
  %  \includeimage[scale=0.9]{RePhorm2Gantt.pdf}
%\hss}}
\label{fig:gantt}
\vspace{-1in} % Fool LaTeX into avoiding unnecessary page break
\endlandscape

\newpage
%\bigskip\bigskip\bigskip

%% Set up the milestone numbers.
\input{milestones}

\fbox{\begin{minipage}{\textwidth}\begin{center}\Large\bf List of Milestones
  \end{center}
  \end{minipage}}
\label{sect:milestones}

\bigskip

\newcounter{ms}
\renewcommand{\thems}{MS\arabic{ms}}
\begin{minipage}{\textwidth}
\begin{center}
 \begin{tabular*}{\textwidth}{|p{1.5cm}|p{8.3cm}|p{1.2cm}|p{0.6cm}|p{4.2cm}|}  \hline
 \textbf{MS No.} & \textbf{Milestone name} & \textbf{Related WPs} & \textbf{Est. date} & \textbf{Means of
   verification} \\ % (success criteria below)} \\ % (deliverables shown here + success criteria below) \\
\hline
MS1 & Initial Requirements Analysis & WP7 & M3 & D7.1 \\
   \hline
\end{tabular*}
\end{center}
\end{minipage}

\setcounter{ms}{0}
\vspace{20pt}
\begin{center}
\begin{tabular*}{\textwidth}{|p{1.2cm}|p{13.3cm}|p{2.2cm}|}\hline
\textbf{MS No.} & \textbf{Success Criteria} & \textbf{Contributes to
  Objective(s)} \\
  \hline
MS1 & Initial Requirements Analysis Completed & \textbf{1 -- 8} \\
  \hline
\end{tabular*}
\end{center}

%\landscape
\newpage
\fbox{\begin{minipage}{\textwidth}\begin{center}\Large\bf List of Deliverables
  \end{center}
  \end{minipage}}
\label{sect:deliverables}

\begin{minipage}{\textwidth}
\begin{center}
\begin{tabular}{|p{0.8cm}|p{9.25cm}|p{0.8cm}|p{1.15cm}|p{1.6cm}|p{0.8cm}|p{0.8cm}|}  \hline
\textbf{Del. no.}              & \textbf{Deliverable name}        & \textbf{WP no.} & \textbf{Lead}
& \textbf{Type}              & \textbf{Dis. level}   & \textbf{Del. date}
\\ \hline

%% Year 1

\ref{mgt:mailinglists}           & Internal and public mailing lists
                                                                  & WP1 &\coordshort{} & OTHER & CO &  1 \\
  \hline \ref{mgt:swrepository} & Internal software repository & WP1 & \coordshort{} & OTHER & CO & 1 \\
\hline \ref{del:pressrelease1} & Press Release Announcing Start of \TheProject{} & \ref{wp:dissem} & \SAshort{} & DEC & PU & 3 \\
\hline \ref{del:website1} & Initial Project Website / Presentation & \ref{wp:dissem} & \SAshort{} & DEC & PU & 3 \\
\hline \ref{mgt:periodic-rep-1} & Project Periodic Report (first year) & WP1 & \coordshort{} & R & CO & 12 \\
\hline \ref{del:dissemplan1} & First Interim Report on Dissemination and Exploitation & \ref{wp:dissem} & \SAshort{} & R & PU & 12 \\
\hline \ref{mgt:periodic-rep-2} & Project Periodic Report (second year) & WP1 & \coordshort{} & R & CO & 24 \\
\hline \ref{del:dissemplan2} & Second Interim Report on Dissemination and Exploitation & \ref{wp:dissem} & \SAshort{} & R & PU & 24 \\
\hline \ref{mgt:periodic-rep-3} & Project Periodic Report (third year) & WP1 & \coordshort{} & R & CO & 36 \\
\hline \ref{del:eval3} & Report on Final Implementation of Benchmarks and Use Cases and Evaluation & WP7 & \SAshort{} & R & PU & 36 \\
\hline \ref{del:roadmapping} & Report on Technical Roadmap & WP7 & \SAshort{} & R & PU & 36 \\	
\hline \ref{del:pressrelease2} & Final Press Release Describing the \TheProject{} Results & \ref{wp:dissem} & \SAshort{} & DEC & PU & 36 \\
\hline \ref{del:website2} & Final Project Website / Presentation & \ref{wp:dissem} & \SAshort{} & DEC & PU & 36 \\
\hline \ref{del:dissemplan3} & Final Report on Dissemination and Exploitation & \ref{wp:dissem} & \SAshort{} & R & PU &  36 \\

\hline
\end{tabular}
\end{center}
\end{minipage}


\comment{JB}{Should we assume that there will be only one review in M18 rather than a yearly one?}

\input{WPs/WPs}
\input{WPs/WP3_SCCH}


% \TODO{Milestones need to be discussed and then described here.}

\bigskip\bigskip\bigskip
%\draftpage
\pagebreak
\fbox{\begin{minipage}{\textwidth}

\begin{center}\Large\bf
Critical Risks for Implementation
\label{sect:risks}
\end{center}
\end{minipage}}

\bigskip
Steps have already been taken to reduce the level of risk within the overall implementation plan.  The table below
identifies the main residual risks that are foreseen.  This register will be maintained
and updated as necessary during the project in order to minimise risk and so to maximise its successful completion.

\bigskip

%\begin{tabular}{| p{3.2cm} | p{1.8cm} | p{1.5cm} | p{10.3cm}  |}  \hline
%\begin{longtable}{| p{3.2cm} | p{1.8cm} | p{1.5cm} | p{10.3cm}  |}  \hline
\begin{longtable}{| p{3.5cm} | p{1.5cm} | p{11.8cm}  |}  \hline
\textbf{Description of risk} & \textbf{WPs\newline involved} & \textbf{Proposed Risk-mitigation measures} \\ \hline
\multicolumn{3}{l}{\ }
\\\hline
XX (Milestone XX). 
\par\vspace{1ex}
\textbf{Severity: Medium}
\par
\textbf{Likelihood: Medium}&
WP2--\ref{wp:eval}  &  
This is an early milestone that defines the overall project direction.  
\\\hline
\end{longtable}
%\newpage

%\vspace{-6pt}
\subsection{Management Structure and Procedures (Figure~\ref{fig:management})}
\label{sect:mgt}

\eucommentary{Describe the organisational structure and the decision-making ( including a list of milestones (table 3.2a)).\\
Explain why the organisational structure and decision-making mechanisms are appropriate to the complexity and scale of the project.\\
Describe, where relevant, how effective innovation management will be addressed in the management structure and work plan.\\
Describe any critical risks, relating to project implementation, that the stated project's objectives may not be achieved. Detail any risk mitigation measures. Please provide a table with critical risks identified and mitigating actions (table 3.2b).}

Responsibility for the overall management and technical
direction of the project will rest with the \emph{Project Coordinator}
(Dr Juliana Bowles, \SA{}) who will be the primary point of
contact with the European Commission. Responsibility for
individual work packages will rest with the \emph{Work Package Team
Leader (WTL)} identified below, who will report to the Project Coordinator.
Where a work package is split across more than one
institution, the day-to-day management of each task will be handled
locally, with the task manager reporting to the WTL.   
% Disputes
% will be resolved at the lowest possible level by an independent
% adjudicator (for disputes between WTLs this will be the Project
% Coordinator, unless he is involved in the dispute).
%
In order to ensure good integration of the project and sound
overall management, the Project Coordinator will convene
annual technical workshops containing representatives from
the entire project team.   These workshops will be open to
invited external researchers/industrialists, including members
of the \emph{Project Advisory Board}, and will usually be
accompanied by a physical meeting of the \emph{Project Steering Committee}. In
addition, the Project Coordinator will convene management
meetings involving the relevant partners and members of the
Project Advisory Board, as necessary and appropriate. These meetings will be
conducted either using video-conferencing, through a
teleconference, or in person, as appropriate and with due consideration to
cost, urgency and effectiveness.  Technical teams
working on a work package that is spread across sites will
coordinate through email, video-conferencing, telephone and
scheduled meetings.  Finally, the research teams will maintain
regular contact with the Project Coordinator and each other
through regular email reports and telephone conversations.
Progress will be carefully monitored with progress reports and
monitoring documents open to inspection by the EU project
monitoring officer. In the event of a serious and urgent matter
involving all partners, the Project Coordinator may also
convene an Extraordinary meeting of the Steering Committee.
%
All project documentation (whether managerial, legal or
technical) will be maintained through a centralised electronic
repository, accessible to all consortium members on an open
basis, and incorporating audit trails concisely recording
reasons for changes etc.  We propose to use either GIT or SVN,
which provide suitable low-cost,  low-overhead solutions that all partners are
familiar with.  Our technical reports will form the basis for
the public deliverables that appear on the project web site.

\begin{figure}[ht!]
\vspace{-0.75in}
\begin{center}
\centerline{\hspace{1in} \hbox to \columnwidth{\hss\includeimage[height=5.7in]{Management}\hss}}
\end{center}
\vspace{-1.8in}
\caption{Management Structure}
\label{fig:management}
\end{figure}

%\begin{figure}[t!]
%\begin{wrapfigure}{l}{0.7\textwidth}
%\vspace{-0.75in}
%\hspace{-1in}
%\begin{center}
%\centerline{\hspace{1in} 
%\hbox to \columnwidth{\hss\includeimage[height=5.7in,trim={0 0 0 2.5cm},clip]{Management}\hss}
%}
%\end{center}
%\vspace{-1.8in}
%\caption{Management Structure}
%\label{fig:management}
%\end{figure}
%\end{wrapfigure}

%\TODO{Update this to reflect the consortium.}

\subsubsection*{Technical Steering Committee}
\vspace{-6pt}

The \emph{Technical Steering Committee} comprises the WTLs, plus the
Project Coordinator (who will act as chair).  Its purpose is to ensure
the effective running of the project on a day-to-day basis, and to
coordinate work across work packages.  In particular the Technical Steering
Committee will be
responsible for the implementation of the directives of the Project Steering
Committee, for the
guidance and monitoring of the technical WPs, for coordination among
WPs, for  the timely preparation, approval, and forwarding to the Commission
of the deliverables produced by the WPs, and for the resolution of conflicts
amongst WPs.  It will meet on a regular basis, usually through a monthly
teleconference.  Meetings may also be convened on request by any member.
% but also in person where necessary.  
Each member of the Technical Steering Committee has one vote,
which may be made by proxy, or in absentia, if necessary.  
Decisions are taken by consensus, if possible, otherwise by majority vote, 
with the
Project Coordinator retaining the casting vote.

\subsubsection*{Project Steering Committee}
\vspace{-6pt}

The \emph{Project Steering Committee} comprises one representative from each partner
(usually the PI), and is chaired by the Project Coordinator.  
The purpose of this committee is to decide
the general technical direction of the project.  It will also
take major decisions on project finances, addition of partners, removal of non-performing
partners, IPR issues, reallocation of workload etc.  It will meet in person
at least once per year, supplemented by more regular teleconference
meetings as required. Extraordinary meetings may also be convened on request by any partner.
Each representative has one vote, which
may be made by proxy if necessary.  Decisions are taken by
consensus, if possible, otherwise by majority vote, with the
Project Coordinator retaining the casting vote.

\subsubsection*{Project Advisory Board}
\vspace{-6pt}

The Project Advisory Board comprises a small group of invited
academics and industrialists who will provide input to the
project on general technical trends and directions, and advise
the steering committee where required.  The initial composition
of the Advisory Board will be determined at the outset of the
project, but we expect to include academic experts from the data-intensive, high-performance and cloud computing, as well as machine learning, compilation, software-defined infrastructures and optimisation domains. We also expect to include senior representatives from the automotive, AI and IoT industry domains. The Coordinator is authorized to 
execute with each member of the EEAB a non-disclosure agreement, which 
terms shall be not less stringent than those stipulated in this 
Consortium Agreement, no later than 30 calendar days after their nomination 
or before any confidential information will be exchanged, whichever date is earlier. 
We have invited senior representatives from Aarhus University, SAP Institute for Digital Government, Ericsson, TypeSafe, British Telecom,
the oil\&gas industries, the Cloud Competency Centre (Dublin),
	and Scottish Enterprise.

\pagebreak
\subsubsection*{Work Package Team Leaders}
\vspace{-6pt}

Work package team leaders (WTLs) are responsible for tracking progress within their work package,
developing metrics for each deliverable at the outset of each
task, ensuring that results are properly reviewed against these
metrics, and consequently providing feedback to the Project Coordinator on the achievement of goals. 
%
WTLs have been chosen on the basis of managerial experience, technical expertise and
commitment to the work package programmes. % , as shown below.

%\begin{figure}[t]
\begin{center}
\begin{tabular}{cc}
\begin{tabular}{|l|l|}\hline
\textbf{WP} & \textbf{WTL}  \\ \hline
WP1 &  Juliana Bowles (\coordshort{}) \\
\hline
\end{tabular}
\end{tabular}
\end{center}
%\caption{Work package team leaders (WTLs).}
%\label{fig:wtls}
%\end{figure}


%\pagebreak
\subsubsection*{Principal Investigators}
\vspace{-6pt}

One principal investigator (PI) will be nominated by each partner.
The PI is responsible for properly managing the budget allocated to the partner and for performing
all the tasks that are carried out by that partner, reporting to the appropriate WTLs where necessary.  PIs
also act as line managers for the researchers/developers employed on the project by the partner.
PIs will usually also act as WTLs for the main WPs that are carried out at that site, and may be allocated their own
technical tasks. They will normally be the partner's representative on the steering committee.
They have been chosen for their technical expertise and experience of line management and budget handling.

\newcounter{partic}

\begin{center}
\begin{tabular}{cc}
\begin{tabular}{|l|l|l|}\hline
& \textbf{Partner} & \textbf{PI} \\ \hline
\addtocounter{partic}{1}
\thepartic & \participantshort{\thepartic} &  Juliana Bowles \\\hline
\end{tabular}
\quad\quad&\quad\quad
\begin{tabular}{|l|l|l|}\hline
& \textbf{Partner} & \textbf{PI} \\ \hline
\addtocounter{partic}{1}
\thepartic & \participantshort{\thepartic} & XX \\\hline
\end{tabular}
\end{tabular}
\end{center}

\vspace{12pt}
\subsubsection*{Project Coordinator}
\vspace{-6pt}

The Project Coordinator is \emph{Dr Juliana Bowles}.  Her role
is to act as the primary point of contact with the European
Commission, to receive feedback on research results from each
work package, to ensure the project maintains effective
progress towards the project objectives based on these results,
to produce any required  project management reports, to ensure
that deliverables are produced according to the planned
schedule and delivered to the Commission and project reviewers
as required, and to resolve disputes between project partners
as and when these arise.  He will convene regular management
and technical meetings, monitor progress on each work package,
collate deliverables, and maintain good contact with each site,
in addition to producing the annual management reports, and
ensuring that each site produces the required financial (audit)
certificates.  He will also be responsible for ensuring that
the Consortium Agreement (including IPR issues, voting rules and the conflict resolution procedures)
and any other legal documents are properly prepared and managed. This will be
done through \SAshort{} \emph{Research and Enterprise
Services}, who have significant expertise in preparing such
agreements.

\vspace{12pt}
\subsubsection*{Project Administrator}
\vspace{-6pt}

The Project Coordinator will be supported in her management
duties by a part-time \emph{Project Administrator} (to be appointed
from staff already employed by \SA{}) and located at \SA{}.  The Administrator
must possess both strong organisational skills and a
sufficient level of technical expertise in order to communicate
management requirements to the Partners, but will not be
involved in the management of day-to-day RTD activities.

\vspace{12pt}
\subsubsection*{Consortium agreement}
\vspace{-6pt}

% The relationship between all partners will be fixed in a Consortium Agreement based on the following principles:

% In order to have a management system applicable through all phases of the
% project, a reasonable approach is to have straight, clear and direct
% management and organization protocol at all levels. This is particularly
% relevant given the challenging financial and industrial policy
% constraints. Therefore, in order to have clearly assigned
% responsibilities, to avoid any friction and to progress as per the
% project plan, the responsibilities and authorities of the project manager
% and the team members will be unambiguous.

The partners will be bound by a formal consortium agreement that is
planned to be signed prior to the beginning of the project of the project,
and in which their roles, responsibilities and mutual obligations will be
defined both for the project life and, where relevant, beyond.  This will
formalise key issues including conflict resolution, IPR procedures, governance structure
etc.  %It will be based on the model consortium agreement issued by the European Commission.
The Digital Europe version of the DESCA, including the European Commission's
inputs will constitute the basis for such consortium agreement.

%\pagebreak
% \vspace{-6pt}
\subsubsection*{Conflict Resolution}
\label{conflict-resolution}
If conflicts arise during the execution of the project, they will be resolved according to the following principles:
% 
% \begin{itemize}
% \item
They will first be addressed within the relevant WP through discussion chaired by the WTL;
% \item
If this fails, the issue will be presented by the WTL either to the Technical Steering Committee
or to the Project Steering Committee, depending on the nature of the problem (technical or business/strategic).
% \item
The relevant board will attempt to resolve the issue through the usual voting procedure.
% \end{itemize}
%
Technical issues between WPs will also be addressed by the Technical Steering Committee.
%  As noted above, the TSC of the project consists of the WP leaders (chaired by the technical coordinator), and the GA consists of representatives of each partner (chaired by the management coordinator).
Any conflicts that cannot be resolved through the principles above will
be handled according to the dispute resolution provision set forth in the
Consortium Agreement.

% \subsubsection*{Management Costs}

% We have budgeted for the Project Administrator at 25\% effort
% over the lifetime of the project (i.e. 9 person-months) at
% \SAshort{}, plus small-scale management effort as required by each support to support the
% project through the preparation of reports for review meetings and other project-level
% management tasks.
% We have also budgeted for the cost of running annual Advisory Committee meetings, including travel
% support for unfunded Advisory Committee members, at \euros{} XX p.a. for a total cost of \euros{} XX.
% We have budgeted an additional
% \euros{}~4,800 for travel by the Project Coordinator (estimated
% as an additional two trips per annum).
% In order to minimise costs and time expenditure, as far as
% possible, all project management activities will be carried out using
% low-cost means such as email, Skype, telephone or
% video-conferencing, and any managerial travel will normally be
% combined with technical or research meetings.  Each site with expenditure
% in excess of \euros{}~325,000 also requires specific costs
% to cover the preparation of the required financial certificates, which will
% generally involve subcontracting an external financial auditor.

\draftpage
\subsection{Consortium as a Whole}
\eucommentary{\begin{itemize}
\item
Describe the consortium. How will it match the project's objectives? How do the members complement one another (and cover the value chain, where appropriate)? In what way does each of them contribute to the project? How will they be able to work effectively together?
\item
If applicable, describe the industrial/commercial involvement in the project to ensure exploitation of the results and explain why this is consistent with and will help to achieve the specific measures which are proposed for exploitation of the results of the project (see section 2.3).
\item
Other countries: If one or more of the participants requesting EU funding is based in a country that is not automatically eligible for such funding (entities from Member States of the EU, from Associated Countries and from one of the countries in the exhaustive list included in General Annex A of the work programme are automatically eligible for EU funding), explain why the participation of the entity in question is essential to carrying out the project
\end{itemize}
}

\begin{figure}[t]
\begin{center}
%\includeimage[scale=0.6,angle=0]{BlessConsortium.pdf}
\end{center}
\vspace{-0.3in}
\caption{Areas of Partner Expertise}
\label{fig:consortium}
\end{figure}

\textbf{Figure~\ref{fig:consortium}} shows the areas of expertise that
are relevant to this project and the consortium partners that
possess that expertise.  All partners span multiple areas,
providing technical depth within the consortium, and avoiding
knowledge gaps.  Within the areas, each partner possesses
complementary expertise, but with enough knowledge overlap to
ensure tight cohesion of the consortium. The consortium
comprises both academic and industrial expertise.
%  from XX
% highly-respected partners.
The consortium links the world-leading technical expertise of
the participating groups on XX.


\paragraph*{Integration of the Consortium.}
%\vspace{-6pt}

Several of the partners already have close working relationships through
recent and ongoing research projects (e.g. \rephrase).
The teams share common technical interests and several are active members in e.g. the
HiPEAC network of excellence (\SAshort{};).
Work Packages have been designed to foster close collaboration
between teams at different organisations, with multiple groups involved in all of
the technical and evaluation work packages. The tasks in 
each work package have been allocated on the basis of
technical expertise and ability. All tasks have been designed to involve multi-site
collaboration and/or the exchange of information, which is
intended to promote healthy interaction between the partners.
Finally, in order to ensure good integration between the partners,
we propose to run at least one technical workshop each year, and
have also requested funds to allow researchers from each group
to visit other groups on a regular basis.  We anticipate that
all of the \TheProject{} researchers will participate in these
technical workshops and exchanges.  We also intend to publish a significant
number of research papers and technical reports deriving from our joint research,
and to collaborate on joint tool production. 
We thus foresee a necessary and close level of integration between
the \TheProject{} partners.

\paragraph{Industrial/Commercial Involvement.}

\TheProject{} directly involves one large company (\IBMshort{}), 
%% sloppy -- KH
XX SMEs.
These organisations have included draft exploitation plans that will directly use the results of the project
as part of their ongoing business strategies and commercial development.
% follows an industrially-inspired agenda and addresses a key and topical challenge in
The \TheProject{} project further engages directly with industry through its
dissemination, user community and outreach activities 
% a dedicated  workpackage (WP7) 
% that are aimed at promoting
will promote the
\TheProject{} tools, technologies and above all \emph{mindset} and \emph{methodology} to a wider user base,
especially through industry-focused events. % that should attract C/C++ programmers and Simulink/SCADE users.
The objective is to ensure widespread uptake of the project results in a broad base of potential industrial
software developers targeting a variety of commercially important domains. % including telecommunications, 3D modelling and the automotive sector.
This will be assisted by including major industry participants on its Advisory Committee,
by actively engaging with the C, C++communities, and by engaging with the ISO C++ Standard Committee and ITU FG-DPM.
% and with the upcoming C++17 design.
% and by actively engaging with new coding standards for parallel and data-intensive applications, as well as C++.
% Finally, members of the consortium are also active members of the ISO C++ Standards Committee. This will
% ensure that the techniques, approach and methodology developed in the \TheProject{} will
% have a broad exposure through the C++ community, and through the evolution of the C++ language
% design itself.

% \khcomment{More needed here.}

\paragraph{Project Management Expertise.}

Members of the team have been heavily involved in running
various national and international research projects.  The
Project Coordinator, Dr Juliana Bowles, has obtained numerous
research grants and awards from national and international
bodies...

As described in the partner descriptions below,
%% Should add activities for INRIA, CodePlay etc.
most of the other partners have been extensively involved in previous and
ongoing EU projects at both technical and managerial
levels, and have dedicated experienced senior staff on the \TheProject{} project.
%XX
%
This experience will be called on as necessary to resolve any
managerial problems that may arise during the course of the
project.


%\bigskip
%\bigskip
\subsection{Resources to be Committed}

\eucommentary{Please provide the following:
\begin{itemize}
\item
a table showing number of person/months required (table 3.4a)
\item
a table showing 'other direct costs' (table 3.4b) for participants where those costs exceed 15\% of the personnel costs (according to the budget table in section 3 of the administrative proposal forms)
\end{itemize}}

\input{resources}

%\pagebreak
\subsubsection{Management Level Description of Resources and Budget}
\vspace{-6pt}

\TODO{This needs to be updated in line with the rest of the
project.}

The project will employ XX person-months of effort over three
years, comprising one or more full-time or part-time researchers at each site
plus one part-time project administrator at \SAshort{}, % and one part-time web designer at \INRIAshort,  Not in PMs?
20\% of the Project Coordinator and 10\% of the WTLs. The researchers will be supported by
the necessary dedicated computing equipment,
% the
% usual basic research equipment (workstations and/or laptop
% computers, network facilities, printers, dedicated file
% servers, etc.) funded from the project overheads, by
% special-purpose heterogeneous hardware necessary to carry out
% the research, 
by funding to enable the necessary travel to scientific and technical conferences, trade shows, 
project meetings and other project-related events, and by the funding that is needed to establish/enhance existing
industrial and academic contacts and to establish a user
community for the \TheProject{} tools and technologies.
%
The quoted budget includes all relevant national social and
other legitimate employment costs as permitted under the rules
governing EU Horizon 2020 ICT projects, including costs of
healthcare, social security and pensions provision, in line with national norms for each site.
%
Sufficient travel funding is also needed to support good
collaboration between the groups, including attendance at the
annual technical project meetings, plus individual visits between
sites. We have budgeted approximately \euros{}~8,000 per
site per year (varied in line with previous
costs at each site)  to cover, for example:
% \begin{itemize}
% \item 
attending two project workshops at \euros{}~600 each;
% \item
attending the annual Project Review Meeting at \euros{}~600;
% \item
one 1-week inter-site visit at \euros{}~750 each;
% \item
attending two conferences per year within the EU at \euros{}~1,000 each;
% \item
attending one conference per year outside the EU at \euros{}~1,500;
%\item
three conference fees per year at \euros{}~650 each.
% \end{itemize}
%
\noindent
In addition, \SAshort{} has budgeted \euros{}~1,500 per year to cover attendance at
IFIP Working Group meetings, visits to industrial concerns for dissemination purposes,
attendance at developer conferences, demonstrations etc. to promote the project,
and \euros~1,000 per year to support travel that is related to the management of the
project.
Wherever possible, travel for different purposes will be
combined into a single trip. We have also budgeted \euros~1,000
per year at \SAshort{} to support attendance by the Project Advisory Board members at
the annual Advisory Board Meetings, where this cannot be met from other sources.

\TODO{Add any specialist equipment.  We might add a serious
  multi-core/multi-GPU machine.}

%\pagebreak
\subsubsection{Additional Partner Costs}
\vspace{-6pt}

\paragraph{Testbed systems and development servers.}
\SAshort{} has budgeted \euros{} XX for a central
server to support the various software and document repositories that are needed by the project, to run the project website and to provide access
to the shared research data that will be generated by the project.

\paragraph{Open Access Publication Fees.}
Each academic partner has budgeted approximately \euros{5,000} to
support gold open access publication for key project publications
(representing about 10-20\% of the expected project output).  The
budget will be pooled if not used by a specific partner, and used to
support further gold open access publication by other partners or
other dissemination activities, as necessary to maximise the overall
success of the project.  There will be no charge for green open access
publication, which will be used for the remainder of the project
publications.

%\vspace{-12pt}
\label{bibliography}
\addcontentsline{toc}{section}{References}

\bibliographystyle{abbrv}
\bibliography{bibliography}


%% Write macro to split Sections 1-3
\Split{1-3}

% ---------------------------------------------------------------------------
%  Section 4: Members of the Consortium
% ---------------------------------------------------------------------------

\newpage

\eucommentary{Page limits do not apply.}

\section{Members of the Consortium}

\eucommentary{Please provide, for each participant, the following (if available):\\
\begin{itemize}
\item
a description of the legal entity and its main tasks, with an explanation of how its profile matches the tasks in the proposal;
\item
a curriculum vitae or description of the profile of the persons, including their gender, who will be primarily responsible for carrying out the proposed research and/or innovation activities;
\item
a list of up to 5 relevant publications, and/or products, services (including widely-used datasets or software), or other achievements relevant to the call content;
\item
a list of up to 5 relevant previous projects or activities, connected to the subject of this proposal;
\item
a description of any significant infrastructure and/or any major items of technical equipment, relevant to the proposed work;
\item
[any other supporting documents specified in the work programme for this call.]
\end{itemize}}

\subsection{Participants}
\Participant{SA}{(\url{http://www.st-andrews.ac.uk})}

\begin{wrapfigure}{R}{2cm}
\vspace{-3.95cm}
\hfill \includeimage{logos/st-andrews-logo.jpg}
\vspace{-1cm}
\end{wrapfigure}

\label{sec:participantUSTAN}

%===============================================================================
The \SAlong{} is the third-oldest in the English-speaking world (founded 1413).
The School of Computer Science was likewise one of the earliest Computer Science departments in the world (founded 1972).
It has established an excellent reputation for its pioneering research in e.g.,
parallel computing, software engineering, programming language design,
software architectures, theoretical computer science and
distributed/mobile systems.  This research expertise has been
recognised through the award of numerous research grants and
awards from the UK and the European Commission.

\vspace{10pt}
\textbf{The \SAlong{} coordinates the \TheProject{} project and
leads work packages WPXX and participates in WPXX on XX.}
\vspace{10pt}

\paragraph{Dr Juliana Bowles} \url{http://www.}


\subsubsection*{Relevant publications}
\begin{itemize}
\item XX
\end{itemize}

\pagebreak
\subsubsection*{Relevant Research Projects}

\begin{itemize}
% \item
% Automatic Prediction of Resource Bounds for Embedded Systems (EmBounded, IST-2004-510255, 2005-2008, \url{http://www.embounded.org});
\item XX
\end{itemize}

\Participant{IBM}{(\url{http://www.research.ibm.com/labs/haifa/)}}


\begin{wrapfigure}{R}{4cm}
\vspace{-2cm}
\hfill \includeimage[width=4cm]{logos/ibm.jpg}
\vspace{-1cm}
\end{wrapfigure}

\ 

%\vspace{24pt}
For more than sixty years, IBM Research, as the world's largest IT research organisation has been the innovation engine of the IBM corporation. Since the beginning of 2000, IBM has spent \$75 billion in R\&D, enabling IBM to deliver key innovations and maintain U.S. patent leadership for the 21st consecutive
year in 2013.
IBM also participates in and contributes to the work of standards consortia, alliances, and formal national and international standards organisations. 
The IBM Haifa Research Lab is IBM's largest research laboratory outside of the United States, 
employing almost 500 researchers, the majority of whom hold doctorate and master degrees in computer science, electrical engineering, mathematics, and related fields. Since its founding in 1972, HRL has conducted world class research vital to IBM's success. R\&D projects are being executed today in areas such as Cognitive computing, Healthcare and Life Sciences, Verification Technologies, Telco, Machine Learning, Cloud Computing, Multimedia, Active Management, Information Retrieval, Programming Environments and Information and Cyber Security. The Quality and Security Department of the IBM Research Haifa includes researchers in the fields of cyber security and privacy. As a multi-disciplinary research area, researchers come from different research domains including verification, data analytic, operating systems and runtime systems, languages and compilers, network systems, and protocols and cloud technologies.
HRL has a long history of successful participation in EU projects. A partial list includes the following: SMESEC (H2020), REPHRASE (H2020), SHARCS (H2020), PINCETTE (FP7, coordinator), RESERVOIR (FP7, coordinator), CloudWave (FP7, coordinator), SHADOWS (FP6, coordinator), CASPAR (FP6), HiPEAC (FP6 + FP7), SARC (FP6), ACOTES (FP7), MilePost (FP7), HYPERGENES (FP7), HERMES (FP7), SAPIR(FP6, coordinator), PROSYD (FP6, coordinator), Modelplex (FP6, coordinator).
The Quality and Security Department develops advanced tools and technologies spanning the entire spectrum of Functional Verification, Code Analysis and Cyber Security.

As a global leader in IT security, IBM offers the strategies, capabilities, and technologies necessary to help organizations in the private and public sectors preemptively protect the organisation from threats and address the complexities and growing costs of security risk management and compliance. IBM is helping to solve essential security challenges including:
\begin{itemize}
\item
  Better secure data and protect privacy
\item
	Control network access and help assure resilience
\item
	Defend mobile and social workplace
\item
	Manage third-party security compliance
\item
	Address new complexity of cloud and virtualization
\item
	Build a risk-aware culture
\end{itemize} 	
To facilitate a comprehensive offering IBM is continuously investing in emerging technologies in the area of security intelligence and has a wide variety of security products and services. IBM is recognized in the industry as a leader in IT cyber security.
In recent years, IBM has acquired several cyber security start-ups in Israel increasing its R\&D presence in the region. IBM has recently also announced the establishment of a Cyber Center of Excellence (CCoE) in Beer-Sheva, Israel. The IBM Haifa Research Lab, as a well recognized IBM research facility and the largest one outside of the US, is collaborating with European research facilities to support the buildup of the CCoE as well as the acquired cyber security start-ups.

\vspace{10pt}
\textbf{IBM leads work package WPXX}

\vspace{10pt}

\paragraph{Michael Vinov}     

\subsubsection*{List of Publications}


%Formal verification:
\begin{itemize}
\item XX
\end{itemize}

\subsubsection*{Relevant Research Projects}
\begin{itemize}
\item
Validating Changes and Upgrades in Embedded Software (PINCETTE, ICT-257647);
\item
CloudWave: Agile Service Engineering for the Future Internet (CloudWave, ICT-610802);
\item
Refactoring Parallel Heterogeneous Resource-Aware Applications --- a Software Engineering Approach (RePhrase, ICT-644235);
\item
Secure Hardware-Software Architectures for Robust Computing Systems (SHARCS, ICT-322014).

\end{itemize}

\Participant{SCCH}{(http://www.scch.at)}

\begin{wrapfigure}{R}{4cm}
\vspace{-2cm}
\hfill \includeimage[width=4cm]{logos/SCCH.jpg}
\vspace{-1cm}
\end{wrapfigure}

\SCCH{} (\url{www.scch.at}) is an Austrian research and technology organisation, funded in 1999 by several institutes of Johannes Kepler University, Linz. Its primary focus is on applied research in the fields of software and data science. 
In projects with partner companies state-of-the-art research results are applied to practical industrial projects to increase and maintain their competitiveness. One of the focus areas is Data Analysis Systems (DAS), specialising on the advancement and application of methods for the analysis and modelling of complex and massive sensor data in its (industrial) application context. Particular application domains include
\begin{inparaenum}[a)]
\item modelling, prognosis, forecast and control of systems
\item industrial fault detection, diagnosis and prognosis
\item the discovery of knowledge and structure in industrial processes.
\end{inparaenum}
\SCCHshort{} is or was involved in the EU-funded projects H2020 ALOHA (Grant Agreement 780788), TRESSPASS (SEC-2016-2017-2, Proposal Nr. 787120) RePhrase (ICT-644235), ParaPhrase (IST-2011-288570), ADVANCE (IST-2010-248828), SECO, and FACETS, where in ALOHA and TRESSPASS SCCH contributes with its expertise in deep learning and the latter are concerned with parallel computation.  The participating investigators are project managers or researchers for relevant applied research projects in the fields of machine learning, parallelisation, and scheduling, and are active in the research community by publishing and reviewing for journals and conferences.

\vspace{10pt}
\textbf{\SCCHshort{} leads WPXX}
\vspace{10pt}

\subsubsection*{List of Publications}

\begin{itemize}

\item XX
  
\end{itemize}

\subsubsection*{Relevant Research Projects}

\begin{itemize}

\item RePhrase (H2020, ICT-644235) - Refactoring Parallel Heterogeneous Resource-Aware Applications. SCCH's role: reinforcement learning based dynamic scheduling and industrial use cases

\item ParaPhrase (IST-2011-288570) - Parallel Patterns for Adaptive Heterogeneous Multicore Systems. SCCH's role: use cases in the area of machine learning

\item ADVANCE (IST-2010-248828) - Asynchronous and Dynamic Virtualisation through performance ANalysis to support Concurrency Engineering, \url{http://www.project-advance.eu});

\item ALOHA (H2020 Grant Agreement 780788) - Software framework for runtime-Adaptive and secure deep Learning On Heterogeneous Architectures. SCCH's role: develop deep transfer learning based methods for surveillance applications

\item TRESSPASS (H2020 SEC-2016-2017-2, Proposal Nr. 787120) - robusT Risk basEd Screening and alert System for PASSengers and luggage. SCCH's role: develop deep learning based methods for security applications

\item GROW (H2020 Grant Agreement No.690199) Citizen Observatory that has ground-truthed Sentinel-1 to improve the accuracy of predictions on extreme events, such as flood, drought and wildfire. \url{https://growobservatory.org};

\item WeObserve (H2020 Grant Agreement No.776740) An Ecosystem of Citizen Observatories for Environmental Monitoring. Umbrella for H2020 projects GROW Observatory, Landsense, Groundtruth 2.0 and Scent \url{https://growobservatory.org};

\end{itemize}

% ============================

\Participant{SOPRA}{(\url{https://www.soprasteria.co.uk/)}}


\begin{wrapfigure}{R}{6cm}
\vspace{-2cm}
\hfill \includeimage[width=6cm]{logos/Sopra-Steria-logo2.png}
\vspace{-1cm}
\end{wrapfigure}

\ 

%\vspace{24pt}

Sopra-Steria, since 1968, supports the primary business areas of consulting services, systems integration, integration of ERP, implementation of applications, as well as providing technical support to users and application maintenance and outsourcing services and operation of professional processes.

Has experience in:

\begin{itemize}
    \item Cyber Security via: (\url{https://www.soprasteria.com/services/cybersecurity})
    \item Artificial Intelligence via:\\ (\url{https://www.soprasteria.com/services/technology-services/artificial-intelligence})
    \item Internet of Things (IoT) via:\\ (\url{https://www.soprasteria.com/services/technology-services/internet-of-things})
\end{itemize}

Supports following industries:
\begin{itemize}
    \item Aerospace
    \item Defense and Security
    \item Energy Utilities
    \item Financial Services
    \item Insurance and Social
    \item Government
    \item Retail
    \item Telecommunication, Media and Entertainment
    \item Transport
\end{itemize}



\vspace{10pt}
\textbf{Sopra-Steria leads work package WPXX}

\vspace{10pt}

\paragraph{Andreas Francois Vermeulen} - Head of Analytics, Digital Consultancy Services within the United-Kingdom.

Andreas has been in information technology industry for forty plus years. He is the consulting delivery head for over hundred consultants in the United-Kingdom. Author of three international books on big data, data science and machine learning.
     

\subsubsection*{List of Publications}

\begin{itemize}
\item The SERUMS tool-chain: ensuring security and privacy of medical data in smart patient-centric healthcare systems. (IEEE Big Data), Los Angeles, December 2019, IEEE Press. DOI: 10.1109/BigData47090.2019.9005600
\end{itemize}

\subsubsection*{Relevant Research Projects}
\begin{itemize}
\item SERUMS (\url{https://www.serums-h2020.org/})
\end{itemize}

% ============================
\Participant{FRQ}{(\url{https://www.frequentis.com/})}

\begin{wrapfigure}{R}{6,2cm}
\vspace{-3cm}
\hfill \includeimage[width=7cm]{logos/FRQ_logo.png}
\vspace{-1cm}
\end{wrapfigure}
\vspace{10pt}

Established in 1947 Frequentis has grown to an international supplier of communication and information systems with an export quota of more than 95\%. The core market is focused on safety critical control room solutions in various domains. Over 2000 employees are working in the corporate headquarters in Vienna, and subsidiaries in more than 50 countries worldwide. Frequentis is a member of SESAR Joint Undertaking and an active participant in numerous researches, regulatory, industry and standardization communities.

Frequentis contributes its expertise in international project and technology know-how as an industry partner in various safety critical domains. Particularly the knowledge as a system integrator in the ATM domain will help to integrate the different components developed by the partners in the project to have successful demonstration and validation in the end. The international knowledge and experience of Frequentis will assure that the consortium possesses the scientific and technological expertise required for Digital Fortress.

%\vspace{10pt}
%\textbf{Frequentis leads work package WPXX}
\vspace{10pt}

\textbf{Key Personnel:}

Eduard Gringinger (male) (PhD, MSc, MSocEcSc, BSc), is senior lead scientist and project manager with more than 10 years of experience in the research areas of safety critical data and services with a business focus on the air traffic management domain. He has work experience in relation with information management, data and service modelling and is member in various EUROCAE, ICAO/AMO working groups. He received a PhD, MSc, and a MSocEcSc with distinctions from Vienna University of Technology.

Christoph Fabinaek (male) (PhD, MSc, MBA), is senior lead scientist. Since 2006, he worked in various roles in safety critical domains at Frequentis. He was consultant for 3 years at AI Informatics and Siemens and is now is chairman of OwnYourData. He received his PhD from the Vienna University of Technology in mathematics (also working at the Innovative Computing Laboratory/University of Tennessee) and an MBA from the Danube University Krems (1 semester at the Weatherhead School of Management in Cleveland, Ohio).

\subsubsection*{List of Publications}

\begin{itemize}
\item C.G. Schuetz, B. Neumayr, M. Schrefl, E. Gringinger and S. Wilson, "Semantics-based summarisation of ATM information: Managing information overload in pilot briefings using semantic data containers", The Aeronautical Journal (2019), 1-27. \url{doi:10.1017/aer.2019.74}
\item E.Gringinger, R.M,Keller, A.Vennesland, C.G.Schuetz, and B.Neumayr, "A Comparative Study of Two Complex Ontologies in Air Traffic Management", in Proc. of the 2019 AIAA/IEEE 38th Digital Avionics Systems Conference (DASC), IEEE, September 2019, in press.
\item E. Gringinger, C. Fabianek, C. Schütz, B. Neumayr, M. Schrefl, A. Vennesland, S. Wilson, "The Semantic Container Approach: Techniques for ontology-based data description and discovery in a decentralized SWIM knowledge base", Proceedings of the SESAR Innovation Days 2018 (SID 2018), December 3-7, 2018, Salzburg, Austria. \url{https://www.sesarju.eu/sites/default/files/documents/sid/2018/papers/SIDs\_2018\_paper\_78.pdf}
\item E. Gringinger, C. Fabianek, C. Schütz, J. Stöbich, B. Neumayr, M. Schrefl, "A Proof-of-Concept Implementation of a Semantic Container Management System for Air Traffic Management", Proceedings of the EDAW 2018 Posters and Demonstrations Session co-located with 21st International Conference on Knowledge Engineering and Knowledge Management (EKAW 2018), November 12-16, 2018, ISSN 1613-0073, pp. 69-72, Nancy, France. \url{https://dblp.org/rec/bib/conf/ekaw/GringingerFSNS18}
\item E. Gringinger, C. Schuetz, B. Neumayr, M. Schrefl and S. Wilson, "Towards a value-added information layer for SWIM: The semantic container approach", 2018 Integrated Communications, Navigation, Surveillance Conference (ICNS), Herndon, VA, 2018, pp. 3G1-1-3G1-14. \url{https://doi.org/10.1109/ICNSURV.2018.8384870}
\item C. Flachberger, E. Gringinger, "Decision Support for Networked Crisis \& Disaster Management - A Comparison with the Air Traffic Management Domain", Information Systems for Crisis Response and Management (ISCRAM), Rio de Janeiro, Brasil, May 22-25, 2016. \url{https://episecc.eu/sites/default/files/1332\_ChristianFlachberger\%2BEduardGringinger2016.pdf}
\end{itemize}


\subsubsection*{Relevant Research Projects, Patents, and Products}

\begin{itemize}

\item SATIE (H2020-SU-INFRA-2018, Grant agreement ID: 832969) - Security of Air Transport Infrastructure of Europe, \url{https://cordis.europa.eu/project/id/832969};

\item SAPIENT (H2020-SESAR-2015-1, Grant agreement ID: 699328) - Satellite and terrestrial architectures improving performance, security and safety in Air Traffic Management (ATM), \url{https://cordis.europa.eu/project/id/699328};

\item PJ19 CI (H2020-SESAR-2015-2, Grant agreement ID: 731765) - Sesar2020 Pj19-03 - Air Traffic Management Systems and Services, \url{https://www.eurocontrol.int/articles/content-integration-sesar-2020-project-pj19-ci};

\item BEST (H2020-Sesar-03-2015, Grant agreement ID: 699298) - Achieving the BEnefits of SWIM by making smart use of Semantic Technologies, \url{http://www.project-best.eu/};

\item Engage (H2020-SESAR-2016-2, Grant agreement ID: 783287) - SESAR Knowledge Transfer Network, \url{https://www.engagektn.com/};

\item SEMCON (ICT of the Future Call 2018 Data Market: 869781) - Semantic Containers for Data Mobility, \url{https://www.ownyourdata.eu/en/semcon/};

\item Patent for prioritization information (EP3118839A1) could be relevant for Digital Fortress, \url{https://patents.google.com/patent/EP3118839A1/en};

\item MosaiX SWIM, the Frequentis ATM informaiton integration platform, \url{https://www.frequentis.com/sites/default/files/support/2018-02/MosaiX\%20SWIM.pdf}; 

\end{itemize}

% ============================




\subsection{Third parties involved in the project (including use of third party resources)}

No third parties are involved in the project.

% ---------------------------------------------------------------------------
%  Section 5: Ethics and Security
% ---------------------------------------------------------------------------

\newpage

\section{Ethics and Security}

\subsection{Ethics}

The proposal raises no specific ethical concerns.


\subsection{Security}

Please indicate if your proposal involves:

\begin{itemize}
\item
activities or results raising security issues: NO
\item
'EU-classified information' as background or results: NO
\end{itemize}

%% Write macro to split Sections 4-5
\Split{4-5}

%% Finalise batch file
\immediate\write\BatchFile{exit}% 
\immediate\closeout\BatchFile% 

\newpage

\label{bibliography}
\addcontentsline{toc}{section}{References}

%\bibliographystyle{abbrv}
%\bibliography{bibliography_ustan}
%\bibliography{bibliography_scch}

\end{document}
